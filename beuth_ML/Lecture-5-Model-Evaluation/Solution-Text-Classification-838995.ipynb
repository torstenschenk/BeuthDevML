{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "In dieser Aufgabe werden Sie eine Text Classification Pipeline bauen, die Partei gegeben einen Text vorhersagt. \n",
    "Statt der Parlamentsdebatten koennen Sie auch gerne einen anderen Text Datensatz nehmen, wenn Sie einen guten finden.\n",
    "Stellen Sie aber sicher, dass Ihre Kollegen Zugriff auf die Daten haben fuer die Korrektur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "if not os.path.exists(DATADIR): \n",
    "    os.mkdir(DATADIR)\n",
    "\n",
    "file_name = os.path.join(DATADIR, 'bundestags_parlamentsprotokolle.csv.gzip')\n",
    "if not os.path.exists(file_name):\n",
    "    url_data = 'https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1'\n",
    "    urllib.request.urlretrieve(url_data, file_name)\n",
    "\n",
    "df = pd.read_csv(gzip.open(file_name), index_col=0).sample(frac=1)\n",
    "# labels\n",
    "parteien = df.partei.unique()\n",
    "# total data length\n",
    "# df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Auszug der Parlamentsdebatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sitzung</th>\n",
       "      <th>wahlperiode</th>\n",
       "      <th>sprecher</th>\n",
       "      <th>text</th>\n",
       "      <th>partei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17300</th>\n",
       "      <td>195</td>\n",
       "      <td>17</td>\n",
       "      <td>Dr. Frank Steffel</td>\n",
       "      <td>Und sie gilt international als Auslaufmodell. ...</td>\n",
       "      <td>cducsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>71</td>\n",
       "      <td>17</td>\n",
       "      <td>Dirk Becker</td>\n",
       "      <td>Mit dem vorliegenden Antrag der SPD beschäftig...</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39586</th>\n",
       "      <td>186</td>\n",
       "      <td>18</td>\n",
       "      <td>Dagmar G. Wöhrl</td>\n",
       "      <td>Auch im Libanon werden die Spannungen angesich...</td>\n",
       "      <td>cducsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36096</th>\n",
       "      <td>144</td>\n",
       "      <td>18</td>\n",
       "      <td>Norbert Müller</td>\n",
       "      <td>Wir haben ein ganzes Bündel von Maßnahmen und ...</td>\n",
       "      <td>linke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sitzung  wahlperiode           sprecher  \\\n",
       "17300      195           17  Dr. Frank Steffel   \n",
       "5400        71           17        Dirk Becker   \n",
       "39586      186           18    Dagmar G. Wöhrl   \n",
       "36096      144           18     Norbert Müller   \n",
       "\n",
       "                                                    text  partei  \n",
       "17300  Und sie gilt international als Auslaufmodell. ...  cducsu  \n",
       "5400   Mit dem vorliegenden Antrag der SPD beschäftig...     spd  \n",
       "39586  Auch im Libanon werden die Spannungen angesich...  cducsu  \n",
       "36096  Wir haben ein ganzes Bündel von Maßnahmen und ...   linke  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitten Sie die Daten in Train (80%) und Test (20%), dafür koennen sie die sklearn train_test_split function benutzen. \n",
    "\n",
    "Dann trainieren Sie eine Pipeline mit einem geeigneten Vectorizer und einem sklearn Modell Ihrer Wahl. \n",
    "\n",
    "Vergleichen Sie die Precision/Recall/F1 und Accuracy auf dem Train und Test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyPerClass (t_labels,predictions, labels, print_res=0):\n",
    "    # calculate accuracy result for each label in prediction result\n",
    "    # t_labals: train of test labels: prediction results\n",
    "    # predictions\n",
    "    cmat = confusion_matrix(t_labels, predictions)\n",
    "    accuracy_arr = np.array(cmat.diagonal()/cmat.sum(axis=1))\n",
    "    if print_res==1:\n",
    "        #print(cmat)\n",
    "        #print(accuracy_arr)\n",
    "        print('accuracy: ', end=' ')\n",
    "        for idx,label in enumerate(labels):\n",
    "            print(label, np.around(accuracy_arr[idx],decimals=3), end=' ')\n",
    "\n",
    "    return accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import for accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# example types\n",
    "\n",
    "# 1.1.1. Ordinary Least Squares\n",
    "# 1.6.5. Nearest Centroid Classifier\n",
    "#from sklearn.neighbors import NearestCentroid\n",
    "# 1.1.12. Stochastic Gradient Descent - SGD\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# new exercise test classifiers\n",
    "# error\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "#\n",
    "# logistic model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put some data aside for model evaluation\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['text'], df['partei'], test_size=0.2)\n",
    "\n",
    "# error!\n",
    "#linreg_clf = Pipeline([('vect', TfidfVectorizer(max_features=int(1e8))),\n",
    "#                            ('clf', LinearRegression())]).fit(train_data, train_labels)\n",
    "\n",
    "logreg_clf = Pipeline([('vect', TfidfVectorizer(max_features=int(1e8))),\n",
    "                        ('clf', LogisticRegression())]).fit(train_data, train_labels)\n",
    "\n",
    "# error not feasible!\n",
    "#svc_clf = Pipeline([('vect', TfidfVectorizer(max_features=int(1e8))),\n",
    "#                        ('clf', SVC())]).fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Logistic Regression on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.94      0.70      0.80     17325\n",
      "         fdp       0.16      0.97      0.28       459\n",
      "      gruene       0.61      0.86      0.72      3583\n",
      "       linke       0.77      0.86      0.81      4398\n",
      "         spd       0.73      0.75      0.74      9178\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     34943\n",
      "   macro avg       0.64      0.83      0.67     34943\n",
      "weighted avg       0.82      0.75      0.77     34943\n",
      "\n",
      "accuracy:  0.752\n",
      "accuracy:  cducsu 0.943 spd 0.163 linke 0.615 gruene 0.772 fdp 0.726 "
     ]
    }
   ],
   "source": [
    "logreg_predictions = logreg_clf.predict(train_data)\n",
    "print(classification_report(logreg_predictions, train_labels))\n",
    "print('accuracy: ',np.around(accuracy_score(train_labels,logreg_predictions),decimals=3))\n",
    "accuracyPerClass (train_labels,logreg_predictions, parteien, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Logistic Regression on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.87      0.60      0.71      4653\n",
      "         fdp       0.06      0.83      0.11        48\n",
      "      gruene       0.35      0.59      0.44       733\n",
      "       linke       0.58      0.68      0.63      1045\n",
      "         spd       0.52      0.55      0.53      2257\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      8736\n",
      "   macro avg       0.48      0.65      0.48      8736\n",
      "weighted avg       0.70      0.60      0.63      8736\n",
      "\n",
      "accuracy:  0.598\n",
      "accuracy:  cducsu 0.87 spd 0.061 linke 0.346 gruene 0.581 fdp 0.519 "
     ]
    }
   ],
   "source": [
    "logreg_predictions = logreg_clf.predict(test_data)\n",
    "print(classification_report(logreg_predictions, test_labels))\n",
    "print('accuracy: ',np.around(accuracy_score(test_labels,logreg_predictions),decimals=3))\n",
    "accuracyPerClass (test_labels,logreg_predictions, parteien, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating SVC on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# error result not feasible\n",
    "#svc_predictions = svc_clf.predict(train_data)\n",
    "#print(classification_report(svc_predictions, train_labels))\n",
    "#accuracyPerClass (train_labels,svc_predictions, parteien, 1);\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#       cducsu       1.00      0.37      0.54     34943\n",
    "#          fdp       0.00      0.00      0.00         0\n",
    "#       gruene       0.00      0.00      0.00         0\n",
    "#        linke       0.00      0.00      0.00         0\n",
    "#          spd       0.00      0.00      0.00         0\n",
    "\n",
    "#    micro avg       0.37      0.37      0.37     34943\n",
    "#    macro avg       0.20      0.07      0.11     34943\n",
    "# weighted avg       1.00      0.37      0.54     34943\n",
    "\n",
    "# accuracy:  cducsu 1.0 spd 0.0 fdp 0.0 linke 0.0 gruene 0.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating SVC on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error result not feasible\n",
    "#svc_predictions = svc_clf.predict(test_data)\n",
    "#print(classification_report(svc_predictions, test_labels))\n",
    "#accuracyPerClass (test_labels,svc_predictions, parteien, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests and comments how to use confusion matrix\n",
    "\n",
    "#import pdb; pdb.set_trace()\n",
    "\n",
    "# not working\n",
    "#for partei in parteien:\n",
    "#    print(partei)\n",
    "#    accuracy_score(train_labels[\\'spd'],logreg_predictions[\\'spd'])\n",
    "    \n",
    "# accuracy_score(train_labels['spd'],logreg_predictions['spd'])    \n",
    "\n",
    "# how to use confusion matrix\n",
    "# from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "# y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "# confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "# array([[2, 0, 0],\n",
    "#        [0, 0, 1],\n",
    "#        [1, 0, 2]])\n",
    "# print('diagonal, label correct predicted')\n",
    "# print('1st col for predicted ants: lower left corner, ant was detected at cat')\n",
    "\n",
    "# cmat = confusion_matrix(train_labels, logreg_predictions, labels=['cducsu'])\n",
    "# cmat = confusion_matrix(train_labels, logreg_predictions, labels=['cducsu', 'gruene', 'spd', 'linke', 'fdp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# f1_score?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
