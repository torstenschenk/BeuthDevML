{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einführung in Lineare Algebra - Einige Grundbegriffe\n",
    "\n",
    "Lineare Algebra ist ein Teil der Mathematik der überall in Wissenschaft und Ingenieurswissenschaften große Verwendung findet. Dennoch haben Informatiker sehr wenig Erfahrung damit. Ein gutes Grundverständnis der Linearen Algebra ist ein vielen Gebieten der Informatik, wie z.B. Computergrafik, Bildverarbeitung oder Machine Learning, notwendig.\n",
    "\n",
    "![Landkarte der Mathematik von Dominic Walliman](./images/map_of_math.jpg)\n",
    "\n",
    "Weiterführende Bücher zu diesem Thema sind _The Matrix Cookbook_ (Petersen and Pedersen, 2006) und _Introduction to Linear Algebra_ (Strang, 2016).\n",
    "\n",
    "Wir werden hier zunächst nur einige Grundlagen ansprechen und später mehr dazu ausarbeiten und tiefer in die Materie einsteigen, aber grundsätzlich auch nur die praktisch relevantesten Themen der Linearen Algebra ansprechen. \n",
    "\n",
    "#### Skalare, Vektoren, Matrizen und Tensoren\n",
    "\n",
    "In der linearen Algebra gibt es unterschiedlichen Typen von mathematischen Objekten:\n",
    "\n",
    "+ __Skalare__: Ein Skalar ist einfach eine Zahl und nicht - wie bei allen anderen Typen - mehrere Zahlen. Diese werden in der mathematischen Notation häufig klein und _kursiv_ beschrieben. Häufig sagt man hier zum Beipiel: \"$n \\in R$ ist der Anstieg einer Kurve\".\n",
    "+ __Vektoren__: Ein Vektor ist ein Array von Zahlen. Die Zahlen sind in einer bestimmten Reihenfolge geordnet. Jeden Eintrag kann man über einen Index erreichen. Typischerweise werden Verktoren in der mathematischen Notation in klein und __fett__ beschrieben z.B. $\\mathbf{v}$. Die Elemente des Vektors werden zumeist _kursiv_ mit dem jeweiligen Index angegeben, z.B. $x_0, x_1, x_2...$. Wenn jeder Element im Vektor eine reelle Zahl ist, also aus $\\mathbb{R}$ kommt und der Vektor $n$ Elemente hat, dann liegt dieser in $\\mathbb{R}^n$, also einem $n$ dimensionalen Raum:\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix}\n",
    "$$. \n",
    "Stellen Sie sich Vektoren als Punkte im Kartesischen Raum vor, wobei jedes Element des Vektors die Koordinate entlang einer Achse ist. \n",
    "+ __Matrizen__: Eine Matrix ist ein 2D Array von Zahlen, wobei jedes Element von zwei Indices identifiziert wird. Die mathematische Notation für Matrizen ist typerweise durch __Großbuchstaben__ z.B. $\\mathbf{A}$. Eine Matrix $\\mathbf{A}$ mit reellen Zahlen und einer Höhe $m$ und einer Breit $n$ wird so augedrückt: $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$. Die Indices für den Elementzugriff werden durch kommaseparierte Integers dargestellt, z.B. $\\mathbf{A}_{0,0}$ bezieht sich auf den obersten linken Eintrag in der Matrix und $\\mathbf{A}_{m,n}$ auf den unteren Rechten. Wir haben hier also $m$ Zeilen und $n$ Spalten - also __nicht__ Breite mal Höhe (wie man das eventuell gewohnt ist), sondern Höhe mal Breite! Mit $\\mathbf{A}_{i,:}$ würde man auf eine ganze Zeile zugreifen, mit $\\mathbf{A}_{:,i}$ auf eine gesamte Spalte.\n",
    "\n",
    "$$ \\mathbf{A} = \\begin{bmatrix} A_{0,0} & A_{0,1} \\\\ A_{1,0} & A_{1,1} \\\\ A_{2,0} & A_{2,1} \\\\ \\end{bmatrix}$$\n",
    "\n",
    "+ __Tensoren__: In manchen Fällen ist es notwendig ein Array mit mal als 2-Achsen zu verwenden. im allgemeinen sagt man zu einem Array in einem regulären Gitter mit einer variablen Anzahl von Achsen $i,j,k$ _Tensor_ $A_{i,j,k}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.4 6.8]]\n",
      "scalar: 1.0\n",
      "vektor: [[0.1 0.2 3.4]]\n",
      "matrix: [[0.1 0.2 3.4]\n",
      " [3.2 0.4 0.2]]\n",
      "tensor: [[[0.21527609 0.60722055]\n",
      "  [0.37600939 0.99149384]\n",
      "  [0.93602389 0.43788636]]\n",
      "\n",
      " [[0.84448353 0.14162374]\n",
      "  [0.07114639 0.4082989 ]\n",
      "  [0.89866438 0.40565918]]\n",
      "\n",
      " [[0.85714332 0.10266042]\n",
      "  [0.21684195 0.77592178]\n",
      "  [0.33166376 0.61886936]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "s = 1.0 # a scalar\n",
    "v = np.matrix([0.1,0.2,3.4]) # vektor in R^3\n",
    "va = np.array([0.1,0.2,3.4]) # gleiche Darstellung aber anderer Numpy Typ mit anderen Operatoren. \n",
    "\n",
    "print(v+v)\n",
    "\n",
    "A = np.matrix([[0.1,0.2,3.4],[3.2,0.4,0.2]])\n",
    "T = np.random.rand(3,3,2)\n",
    "\n",
    "print(\"scalar:\",s)\n",
    "print(\"vektor:\",v)\n",
    "print(\"matrix:\",A)\n",
    "print(\"tensor:\",T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transponierte\n",
    "\n",
    "Die Transponierte einer Matrix kann man sich als Spiegelung an der Diagonale vorstellen $(A^T)_{i,j} = A_{j,i}$:\n",
    "\n",
    "$$ \\mathbf{A} = \\begin{bmatrix} A_{0,0} & A_{0,1} \\\\ A_{1,0} & A_{1,1} \\\\ A_{2,0} & A_{2,1} \\\\ \\end{bmatrix}$$\n",
    "\n",
    "$$ \\mathbf{A^T} = \\begin{bmatrix} A_{0,0} & A_{0,1} & A_{0,2} \\\\ A_{1,0} & A_{1,1} & A_{1,2} \\\\ \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Vektoren kann man als Matrizen mit nur einer Spalte verstehen. Die Transponierte eines Vektors ist eine einzeilige Matrix. Häufig schreibt man in Lehrbüchern einen Vektor erstmal als einzeilige Matrix und transponiert ihn dann zu einem Standard Spaltenvektor, z.B. $x = [x_0, x_1, x_2]^T$\n",
    "\n",
    "Ein Skalar kann man auch als Matrix mit einem einzelnen Eintrag verstehen. Dann ist $a = a^T$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.2 3.4]\n",
      " [3.2 0.4 0.2]]\n",
      "[[0.1 3.2]\n",
      " [0.2 0.4]\n",
      " [3.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.matrix([[0.1,0.2,3.4],[3.2,0.4,0.2]])\n",
    "A_t = A.T\n",
    "print(A)\n",
    "print(A_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition und Multiplikation von Matrizen und Vektoren\n",
    "\n",
    "Solange Matrizen die gleiche Anzahl an Zeilen und Spalten haben, kann man sie einfach addieren bzw. subtrahieren. Dabei werdern die jeweiligen Elemente addiert bzw. subtrahiert.\n",
    "\n",
    "$$ C = A + B $$ wobei gilt $$ C_{i,j} = A_{i,j} + B_{i,j}$$\n",
    "\n",
    "Wir können auch Skalare auf eine Matrix addieren oder diese damit multiplizieren. Auch diese Operation wird auf jedes Element ausgeführt. \n",
    "$$ D = a \\cdot B + c $$ wobei gilt $$ D_{i,j} = a \\cdot B_{i,j} + c$$\n",
    "\n",
    "Manchmal lässt man (insbesondere im Machine Learning) bei der Implementierung eine weniger gewöhnliche Operation zu.\n",
    "Diese erlaubt die Addition eines Vektors auf die Zeilen der Matrix. Das erlaubt eine einfachere Handhabung und man muss nicht erst eine Matrix mit den Werten von $b$ erzeugen. In Numpy wird diese Operation Broadcasting genannt und funktioniert so:\n",
    "$$ C = A +b $$ wobei gilt $$ C_{i,j} = A_{i,j} + b_j $$\n",
    "\n",
    "Die wichtigste Operation von Matrizen ist die Multiplikation von zwei Matrizen. Das Produkt zweier Matrizen $A$ und $B$ ergibt die Matrix $C$. \n",
    "Damit man zwei Matrizen miteinander multiplizieren kann muss $A$ dieselbe Anzahl von Spalten haben wie $B$ Zeilen. Also wenn $A$ die Form $ m \\times n$ hat und $B$ die Form $ n \\times p $, dann ergibt sich für $C$ die Form $ m \\times p$. Mathematisch ist das so definiert:\n",
    "$$ C = AB $$\n",
    "bzw.\n",
    "$$\\mathbf{C_{i,j}} = \\sum \\mathbf{A_{i,k}} \\mathbf{B_{k,j}}$$\n",
    "\n",
    "[Matrixmultiplikation](http://matrixmultiplication.xyz/) ganz anschaulich und zum Mitrechnen.\n",
    "\n",
    "\n",
    "Das Innenprodukt oder Skalarprodukt zwischen zwei Vektoren $x$ und $y$ der gleichen Dimensionalität (bzw. in diesem Zusammenhang zwei jeweils einspaltigen Matrizen) ist auch das Produkt zweier Matrizen $x^T y$.  \n",
    "Man kann sich also vorstellen, dass man das Matrixprodukt $C=AB$ auch so verstehen kann, dass man $C_{i,j}$ berechnet als Innenprodukt zwischen der i-ten Zeile von $A$ und der j-ten Spalte von $B$. Matrix Operationen haben einige wichtige Eigenschaften, z.B. ist die Matrixmultiplikation distributiv \n",
    "\n",
    "$$ A(B+C) == AB + AC$$\n",
    "\n",
    "und assoziativ:\n",
    "\n",
    "$$ A(BC) == (AB)C$$\n",
    "\n",
    "Dieses Produkt ist __nicht kommutativ__. Also gilt $$ AB = BA$$ nicht immer. \n",
    "Allerdings ist das Innenprodukt kommutativ:\n",
    "$$ x^Ty = y^Tx$$\n",
    "\n",
    "Die Transponierte hat die Form \n",
    "$$ (AB)^T = B^T A^T$$ \n",
    "\n",
    "Es gibt natürlich noch mehr Eigenschaften von Matrizen, die alle im allgemeinen wichtig sind, für diesen Kurs aber erstmal nicht im Vordergrund stehen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 6 8]\n",
      " [4 6 8]\n",
      " [4 6 8]]\n",
      "[[18 24 30]\n",
      " [18 24 30]\n",
      " [18 24 30]]\n",
      "[[1.5 2.5 3.5]\n",
      " [1.5 2.5 3.5]\n",
      " [1.5 2.5 3.5]]\n",
      "[[0.51980701 0.10540112 0.44872967 0.16239306 0.04887561]\n",
      " [0.34174475 0.64017516 0.55607639 0.17596048 0.22553941]\n",
      " [0.48581111 0.00518661 0.12895824 0.65933253 0.64930215]\n",
      " [0.72081648 0.45747021 0.83493395 0.78890634 0.94186701]]\n",
      "[[0.02696539 0.62677482 0.28696159]\n",
      " [0.08947434 0.9365594  0.57120821]\n",
      " [0.62315718 0.31986205 0.55872277]\n",
      " [0.84310169 0.31692415 0.51351871]\n",
      " [0.18079907 0.63482041 0.14839465]]\n",
      "[[0.44882714 0.65054147 0.55073087]\n",
      " [0.60214741 1.19056995 0.89826131]\n",
      " [0.767203   0.97174924 0.64935622]\n",
      " [1.41608097 1.99524121 1.47954019]] (4, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.matrix('1 2 3; 1 2 3; 1 2 3')\n",
    "B = np.matrix('3 4 5; 3 4 5; 3 4 5')\n",
    "c = np.matrix('0.5 0.5 0.5')\n",
    "print(A+B)\n",
    "print(A*B)\n",
    "print(A+c)\n",
    "\n",
    "A = np.random.random((4,5))\n",
    "B = np.random.random((5,3))\n",
    "C = np.dot(A,B)\n",
    "print(A)\n",
    "print(B)\n",
    "print(C, C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gleichungssysteme \n",
    "\n",
    "Ein wichtiges Element, dass uns auch den Kurs über begleiten wird, sind lineare Gleichungssysteme der Form\n",
    "$$ Ax = b$$\n",
    "wobei $A \\in \\mathbb{R}^{m \\times n}$ eine bekannte Matrix ist, $b \\in \\mathbb{R}^{m}$ ein bekannter Vektor und $x \\in \\mathbb{R}^{n}$ ein Vektor mit uns unbekannten Variablen nach denen wir __lösen__ wollen. \n",
    "\n",
    "Jede Zeile von $A$ und jedes Element von $b$ gibt uns dafür jeweils einen Zusammenhang (_Constraint_). Damit lässt sich die obige Gleichung auch wie folgt aufschreiben:\n",
    "\n",
    "$$ A_{1,:} x = b_1 \\\\ A_{2,:} x = b_2 \\\\ A_{m,:} x = b_m$$\n",
    "\n",
    "bzw expliziter (__Wichtig__: Diese Darstellung wird noch wichtig für das Verständnis).\n",
    "\n",
    "$$ \n",
    "A_{1,1} x_1 + A_{1,2} x_2 + A_{1,3} x_3 + \\dots + A_{1,n} x_n = b_1 \\\\ \n",
    "A_{2,1} x_1 + A_{2,2} x_2 + A_{2,3} x_3 + \\dots + A_{2,n} x_n = b_2 \\\\\n",
    " \\dots \\\\\n",
    "A_{m,1} x_1 + A_{m,2} x_2 + A_{m,3} x_3 + \\dots + A_{m,n} x_n = b_m \\\\ \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identität und Inverse Matrix\n",
    "\n",
    "Ein sehr wichtiges Werkzeug der Linearen Algebra ist die Inverse einer Matrix. Diese erlaubt uns das oben genannte Gleichungssystem zu lösen. Um die Inverse einer Matrix zu verstehen, müssen wir uns erstmal das Konzept der Einheitsmatrix anschauen. \n",
    "Eine Einheitsmatrix ändert einen Vektor nicht, wenn er mit dieser Matrix multipliziert wird. D.h. sie erhält einen n-dimensionalen Vektor. Die Einheitsmatrix ist definiert als $I_n \\in \\mathbb{R}^{n \\times n}$ und es gilt\n",
    "\n",
    "$$ I_n x = x $$\n",
    "\n",
    "Die Struktur der Identitätsmatrix ist sehr einfach. Auf der Diagonalen stehen Einsen, sonst überall Nullen.  \n",
    "\n",
    "$$ \\mathbf{A} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix}$$\n",
    "\n",
    "Die Inverse von $A$ wird dann als $A^{-1}$ bezeichnet und ist folgendermaßen definiert:\n",
    "\n",
    "$$ A^{-1} A = I $$\n",
    "\n",
    "D.h. ein Gleichungssystem kann man folgendermaßen lösen:\n",
    "\n",
    "$$ \n",
    "Ax = b \\\\\n",
    "A^{-1} A x = A^{-1} b \\\\\n",
    "I_nx = A^{-1} b \\\\\n",
    "x = A^{-1}b\n",
    "$$\n",
    "\n",
    "D.h. um ein Gleichungssystem lösen zu können brauchen wir die Inverse der Matrix $A$: $A^{-1}$. Ob diese Matrix erzeugt werden kann, werden wir gleich klären. Leider ist es aber so, dass das Konzept der Inversen $A^{-1}$ eher theoretischer Natur ist und in den meisten praktischen Bereichen nicht wirklich benutzt wird, weil es bei der Berechnung von $A^{-1}$ immer wieder zu Gleitkommadarstellungsproblemen am Computer kommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16666667  0.66666667]\n",
      " [ 0.16666667 -0.33333333]] [[ 6 12]\n",
      " [ 3  3]] [[30]\n",
      " [ 9]]\n",
      "[[1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# Schulbuchbeispiel mit Äpfel und Birnen\n",
    "# 6 Äpfel und 12 Birnen kosten 30 Euro\n",
    "# 3 Äpfel und 3 Birnen kosten 9 Euro\n",
    "# Was ist der Preis des Obstes?\n",
    "A = np.matrix('6 12; 3 3')\n",
    "b = np.matrix('30; 9')\n",
    "A_inv = np.linalg.inv(A)\n",
    "x = A_inv * b\n",
    "print(A_inv, A, b)\n",
    "print(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lineare Abhängigkeit, lineare Hülle und Rang\n",
    "\n",
    "$A^{-1}$ existiert nur dann, wenn $Ax=b$  für jedes $b$ genau eine Lösung hat. Es ist jedoch auch möglich, dass das Gleichungssystem keine oder unendliche viele Lösungen für $b$ hat. \n",
    "\n",
    "Um herauszufinden wieviele Lösungen das LGS (Lineares Gleichungssystem) hat, kann man sich vorstellen, dass die Spalten der Matrix $A$ verschiedene Richtungsvektoren vom Koordinatenursprung (Vektor mit nur Nullen) darstellen und damit bestimmt werden kann wieviele Wege es gibt um $b$ zu erreichen (der ja im gleichen Raum zu finden ist).\n",
    "Jedes Element in $x$ wäre dann in dieser Betrachtung der Skalierungswert des jeweiligen Richtungsvektors und würde uns sagen, wie weit wir in dieser Richtung gehen müssen um bei $b$ anzukommen:\n",
    "$$\n",
    "Ax = \\sum_i x_i A_{i,:}\n",
    "$$\n",
    "\n",
    "Im allgemeinen wird diese Operation auch als __Linearkombination__ bezeichnet. Formal ist eine Linearkombinaton von den Vektoren $v(1), \\dots v(n) $ gegeben durch die Multiplikation jedes Vektors $v(i)$ durch den korrespondierenden skalaren Koeffizienten und deren Addition:\n",
    "$$ \\sum_i c_i v^{(i)}$$\n",
    "\n",
    "Der Span (der auch Lineare Hülle) von den Vektoren ist dann die Menge aller Punkte, die durch die Linearkombination der Originalvektoren erreicht werden kann. Um zu bestimmen ob $Ax=b$ eine Lösung hat, muss man jetzt testen ob $b$ in der linearen Hülle von $A$ liegt (also durch die Skalierung der einzelnen Spalten erreicht werden kann) - wird auch häufig _column space_ genannt.\n",
    "\n",
    "__Beispiel:__ Wenn $A$ eine $3 \\times 2$ Matrix ist und damit $b$ ein 3D Punkt, $x$ ist nur 2D. Also die Modifikation von $x$ kann uns maximal eine 2D Ebene in $\\mathbb{R}^3$ aufspannen. Die Gleichung hat also nur dann eine Lösung wenn der Punkt $b$ auf der Ebene liegt. \n",
    "\n",
    "Die Größe der Matrix $A$ ist aber nicht unbedingt ausschlaggebend. Angenommen man hat eine $2 \\times 2$ Matrix deren Spalten identisch sind. Diese hätte dann die gleiche Lineare Hülle wie eine $2 \\times 1$ Matrix. \n",
    "Diese Abhängigkeit zwischen Spalten oder auch Zeilen nennt man __lineare Abhängigkeit__. Man sagt, dass eine Menge von Vektoren lineare unabhängig sind, wenn keiner dieser Vektoren durch eine Linearkombination eines anderen dargestellt werden kann. \n",
    "\n",
    "D.h. um eine Inverse der Matrix $A$ zu haben und $Ax = b$ lösen zu können, brauche ich also mindestens $m$ linear unabhängige Spalten. Anderenfalls gibt es mehr als einen Weg zum Lösungspunkt. Damit muss die Matrix $A$ eigentlich __quadratisch__ sein und $m=n$ linear unabhängige Spalten haben. \n",
    "Eine quadratsche Matrix, die diese Eigenschaften __nicht__ erfüllt nennt man auch __singulär__. In diesem Fall ist auch die Determinante 0. \n",
    "\n",
    "Es ist immer noch möglich dafür eine Lösung zu finden, aber dann nicht mehr über die Inverse der Matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spezielle Matrizen\n",
    "\n",
    "Symmetrische Matrizen haben die Eigenschaft:\n",
    "$$\n",
    "A = A^T\n",
    "$$\n",
    "\n",
    "Orthogonale Matrizen zeichnen sich durch folgendes aus:\n",
    "\n",
    "$$\n",
    "A^T A = AA^T = I \\\\\n",
    "A^{-1} = A^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norm\n",
    "\n",
    "Manchmal ist es notwendig die Länge eines Vektors zu messen (oder auch die Länge zwischen Vektoren). Dies passiert über der Funktion _norm_. Allgemein definiert man eine $L^p$-Norm als\n",
    "\n",
    "$$\n",
    "|| x ||_p = \\left( \\sum_i |x_i|^p \\right)^{1/p}\n",
    "$$ \n",
    "\n",
    "für alle $p \\geq 1$. Für $p=2$ ergibt sich daraus die Euklidische Länge/Distanz, die jeder von Ihnen kennt. Diese nennt man dann auch $L^2$ Norm. Normen haben im allgemeinen unterschiedliche Eigenschaften, die in für die jeweilige Anwendungen abgewogen werden müssen. Z.B. steigen die Werte der $L^2$ Norm zu Beginng sehr wenig. Bei der $L^1$ Norm ist das dagegen nicht der Fall. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.4142135623730951 1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "a = np.matrix('1 1')\n",
    "l1_norm = np.linalg.norm(a,ord=1)\n",
    "l2_norm = np.linalg.norm(a,ord=2)\n",
    "standard_norm = np.linalg.norm(a)\n",
    "print(l1_norm, l2_norm, standard_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operationen zwischen Vektoren \n",
    "\n",
    "Das Skalar- bzw. Innenprodukt stellt eine Winkelbeziehung zwischen zwei Vektoren $\\mathbf{a}$ und $\\mathbf{b}$ her. \n",
    "$$\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\sum_i^n a_i b_i = a_1b_1 + a_2b_2 + \\dots + a_nb_n = \\| a\\|  \\| b\\|  cos(\\alpha)\n",
    "$$\n",
    "\n",
    "Diese Beziehung kann auch als Projektion des einen Vektors auf den anderen interpretiert werden, wobei das Skalarprodukt der Länge der Projektion entspricht. Hier finden Sie dazu auch nochmal eine gute Online-demo:\n",
    "[Skalarprodukt](http://www.falstad.com/dotproduct/)\n",
    "\n",
    "![Skalarprodukt](https://upload.wikimedia.org/wikipedia/commons/a/ac/Dot-product-2.svg)\n",
    "\n",
    "Das Kreuzprodukt wird auch als das äußere Produkt zwischen Vektoren bezeichnet. Das Kreuzprodukt zwischen den Vektoren $\\mathbf{a}$ und $\\mathbf{b}$ ist ein Vektor, der senkrecht zu $\\mathbf{a}$ und $\\mathbf{b}$ ist. Die Länge des Vektors entspricht dem Flächeninhalt des aufgespannten Parallelograms.\n",
    "\n",
    "$$\n",
    "\\mathbf{a} \\times \\mathbf{b} = \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} \\times \\begin{pmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{pmatrix} = \\begin{pmatrix} a_1b_2 - a_2b_1 \\\\ a_2b_0 - a_0b_2\\\\ a_0b_1 - a_1b_0 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "![Kreuzprodukt](https://upload.wikimedia.org/wikipedia/commons/4/4e/Cross_product_parallelogram.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70710678]]\n",
      "[[0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.matrix('1 0 0')\n",
    "b = np.matrix('1 1 0')\n",
    "a_norm = np.linalg.norm(a,ord=2)\n",
    "b_norm = np.linalg.norm(b,ord=2)\n",
    "print(np.dot(a/a_norm,b.T/b_norm))\n",
    "print(np.cross(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
