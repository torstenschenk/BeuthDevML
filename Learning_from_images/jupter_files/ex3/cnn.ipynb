{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code inspireed by\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#model-training-and-validation-code\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "root = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = datasets.FashionMNIST(root=root, train=True, transform=transform, download=True)\n",
    "test_set = datasets.FashionMNIST(root=root, train=False, transform=transform, download=True)\n",
    "\n",
    "# hyperparameter\n",
    "# TODO Find good hyperparameters\n",
    "# batch_size = ...\n",
    "# num_epochs = ...\n",
    "# learning_rate = ...\n",
    "# momentum = ...\n",
    "\n",
    "# Load train and test data\n",
    "data_loaders = {}\n",
    "data_loaders['train'] = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "data_loaders['test'] = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "# implement your own NNs\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        return x\n",
    "\n",
    "    def name(self):\n",
    "        return \"MyNeuralNetwork\"\n",
    "\n",
    "## training\n",
    "model = MyNeuralNetwork()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "best_acc = 0.0\n",
    "since = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(data_loaders[phase]):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('{} Batch: {} of {}'.format(phase, batch_idx, len(data_loaders[phase])))\n",
    "\n",
    "        epoch_loss = running_loss / len(data_loaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(data_loaders[phase].dataset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'test' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if phase == 'test':\n",
    "            test_acc_history.append(epoch_acc)\n",
    "            test_loss_history.append(epoch_loss)\n",
    "        if phase == 'train':\n",
    "            train_acc_history.append(epoch_acc)\n",
    "            train_loss_history.append(epoch_loss)\n",
    "\n",
    "    print()\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "acc_train_hist = []\n",
    "acc_test_hist = []\n",
    "\n",
    "acc_train_hist = [h.cpu().numpy() for h in train_acc_history]\n",
    "acc_test_hist = [h.cpu().numpy() for h in test_acc_history]\n",
    "\n",
    "plt.title(\"Validation/Test Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation/Test Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),acc_train_hist,label=\"Train\")\n",
    "plt.plot(range(1,num_epochs+1),acc_test_hist,label=\"Test\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Validation/Test Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation/Test Loss\")\n",
    "plt.plot(range(1,num_epochs+1),train_loss_history,label=\"Train\")\n",
    "plt.plot(range(1,num_epochs+1),test_loss_history,label=\"Test\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "examples = enumerate(data_loaders['test'])\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "with torch.no_grad():\n",
    "  output = model(example_data)\n",
    "\n",
    "categories = {\n",
    "    0:\t'T-shirt/top',\n",
    "    1:\t'Trouser',\n",
    "    2:\t'Pullover',\n",
    "    3:\t'Dress',\n",
    "    4:\t'Coat',\n",
    "    5:\t'Sandal',\n",
    "    6:\t'Shirt',\n",
    "    7:\t'Sneaker',\n",
    "    8:\t'Bag',\n",
    "    9:\t'Ankle boot'\n",
    "}\n",
    "\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Pred: {}\".format(\n",
    "      categories[output.data.max(1, keepdim=True)[1][i].item()]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
