{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 1.075386\n",
      "iteration 10: loss 0.332009\n",
      "iteration 20: loss 0.467873\n",
      "iteration 30: loss 0.363600\n",
      "iteration 40: loss 0.382599\n",
      "iteration 50: loss 0.258563\n",
      "iteration 60: loss 0.563396\n",
      "iteration 70: loss 0.194055\n",
      "iteration 80: loss 0.285986\n",
      "iteration 90: loss 0.094028\n",
      "iteration 100: loss 0.155460\n",
      "iteration 110: loss 0.120827\n",
      "iteration 120: loss 0.190392\n",
      "iteration 130: loss 0.175921\n",
      "iteration 140: loss 0.135299\n",
      "iteration 150: loss 0.150288\n",
      "iteration 160: loss 0.111218\n",
      "iteration 170: loss 0.229137\n",
      "iteration 180: loss 0.097084\n",
      "iteration 190: loss 0.069336\n",
      "iteration 200: loss 0.194113\n",
      "iteration 210: loss 0.124443\n",
      "iteration 220: loss 0.176838\n",
      "iteration 230: loss 0.140258\n",
      "iteration 240: loss 0.046282\n",
      "iteration 250: loss 0.078600\n",
      "iteration 260: loss 0.090144\n",
      "iteration 270: loss 0.014306\n",
      "iteration 280: loss 0.031836\n",
      "iteration 290: loss 0.010227\n",
      "iteration 300: loss 0.087716\n",
      "iteration 310: loss 0.052833\n",
      "iteration 320: loss 0.062160\n",
      "iteration 330: loss 0.041752\n",
      "iteration 340: loss 0.014499\n",
      "iteration 350: loss 0.068749\n",
      "iteration 360: loss 0.011301\n",
      "iteration 370: loss 0.049475\n",
      "iteration 380: loss 0.032384\n",
      "iteration 390: loss 0.056472\n",
      "iteration 400: loss 0.062328\n",
      "iteration 410: loss 0.022666\n",
      "iteration 420: loss 0.028299\n",
      "iteration 430: loss 0.007963\n",
      "iteration 440: loss 0.023328\n",
      "iteration 450: loss 0.009940\n",
      "iteration 460: loss 0.008770\n",
      "iteration 470: loss 0.026545\n",
      "iteration 480: loss 0.005290\n",
      "iteration 490: loss 0.004627\n",
      "Test output (values / pred_id / true_id): tensor([[0.1454, 0.4510, 0.1240]]) tensor(1) 1\n",
      "Test output (values / pred_id / true_id): tensor([[ 0.9537, -0.3666,  0.5514]]) tensor(0) 0\n",
      "Test output (values / pred_id / true_id): tensor([[0.1208, 0.2515, 0.6046]]) tensor(2) 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# show plot first run\n",
    "%matplotlib inline \n",
    "# test autocompletion with tab or tab+shift\n",
    "%config IPCompleter.greedy=True \n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "nn_img_size = 32\n",
    "num_classes = 3\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 500\n",
    "batch_size = 4\n",
    "\n",
    "loss_mode = 'mse' \n",
    "#loss_mode = 'crossentropy' \n",
    "\n",
    "loss_train_hist = []\n",
    "\n",
    "##################################################\n",
    "## Please implement a two layer neural network  ##\n",
    "##################################################\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return torch.clamp(x, min=0.0)\n",
    "\n",
    "def relu_derivative(output):\n",
    "    \"\"\"derivative of the ReLU activation function\"\"\"\n",
    "    output[output <= 0] = 0\n",
    "    output[output>0] = 1\n",
    "    return output\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"softmax function to transform values to probabilities\"\"\"\n",
    "    #print('in z:',z)\n",
    "    z -= z.max()\n",
    "    z = torch.exp(z)\n",
    "    sum_z = z.sum(1, keepdim=True)\n",
    "    #print('div z:',z / sum_z)\n",
    "    return z / sum_z \n",
    "\n",
    "def loss_mse(activation, y_batch):\n",
    "    \"\"\"mean squared loss function\"\"\"\n",
    "    # use MSE error as loss function \n",
    "    # Hint: the computed error needs to get normalized over the number of samples\n",
    "    loss = (activation - y_batch).pow(2).sum() \n",
    "    mse = 1.0 / activation.shape[0] * loss\n",
    "    return mse\n",
    "\n",
    "def loss_crossentropy(activation, y_batch):\n",
    "    \"\"\"cross entropy loss function\"\"\"\n",
    "    batch_size = y_batch.shape[0]\n",
    "    loss = ( - y_batch * activation.log()).sum() / batch_size\n",
    "    return loss\n",
    "\n",
    "def loss_deriv_mse(activation, y_batch):\n",
    "    \"\"\"derivative of the mean squared loss function\"\"\"\n",
    "    dCda2 = (1 / activation.shape[0]) * (activation - y_batch)\n",
    "    return dCda2\n",
    "\n",
    "def loss_deriv_crossentropy(activation, y_batch):\n",
    "    \"\"\"derivative of the mean cross entropy loss function\"\"\"\n",
    "    #print('activ:', activation)\n",
    "    #print('y_batch:',y_batch)\n",
    "    batch_size = y_batch.shape[0]\n",
    "    dCda2 = activation\n",
    "    dCda2[range(batch_size), np.argmax(y_batch, axis=1)] -= 1\n",
    "    dCda2 /= batch_size\n",
    "    #print('dCda2:',dCda2)\n",
    "    return dCda2\n",
    "\n",
    "def setup_train():\n",
    "    \"\"\"train function\"\"\"\n",
    "    # load and resize train images in three categories\n",
    "    # cars = 0, flowers = 1, faces = 2 ( true_ids )\n",
    "    train_images_cars = glob.glob('./images/db/train/cars/*.jpg')\n",
    "    train_images_flowers = glob.glob('./images/db/train/flowers/*.jpg')\n",
    "    train_images_faces = glob.glob('./images/db/train/faces/*.jpg')\n",
    "    train_images = [train_images_cars, train_images_flowers, train_images_faces]\n",
    "    num_rows = len(train_images_cars)+len(train_images_flowers) +len(train_images_faces)\n",
    "    X_train = torch.zeros((num_rows, nn_img_size*nn_img_size))\n",
    "    y_train = torch.zeros((num_rows, num_classes))\n",
    "\n",
    "    counter = 0\n",
    "    for (label, fnames) in enumerate(train_images):\n",
    "        for fname in fnames:\n",
    "            #print(label, fname)\n",
    "            img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (nn_img_size, nn_img_size) , interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # print( label, \" -- \", fname, img.shape)\n",
    "\n",
    "            # fill matrices X_train - each row is an image vector\n",
    "            # y_train - one-hot encoded, put only a 1 where the label is correct for the row in X_train\n",
    "            y_train[counter, label] = 1\n",
    "            X_train[counter] = torch.from_numpy(img.flatten().astype(np.float32))\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "    # print(y_train)\n",
    "    return X_train, y_train\n",
    "\n",
    "def forward(X_batch, y_batch, W1, W2, b1, b2):\n",
    "    \"\"\"forward pass in the neural network \"\"\"\n",
    "    ### YOUR CODE ####\n",
    "    # please implement the forward pass\n",
    "    # \n",
    "    #print(type(X_batch))\n",
    "    #print(type(W1))\n",
    "    #print(type(b1))\n",
    "    \n",
    "    m1 = torch.mm(X_batch, W1)+b1\n",
    "    #print(tmp.shape)\n",
    "    #m1 = torch.add(tmp,b1)\n",
    "    #print(m1.shape)\n",
    "    a1 = relu(m1)\n",
    "    #print(a1.shape)\n",
    "    \n",
    "    #m2 = torch.mm(a1, W2)+b2\n",
    "    #a2 = relu(m2)\n",
    "    \n",
    "    # if not relu(m2) in use\n",
    "    if loss_mode == 'mse':\n",
    "        a2 = torch.mm(a1, W2)+b2\n",
    "        loss = loss_mse(a2, y_batch)\n",
    "    else:\n",
    "        m2 = torch.mm(a1, W2)+b2\n",
    "        a2 = softmax(m2)\n",
    "        loss = loss_crossentropy(a2, y_batch)\n",
    "        \n",
    "    #self made\n",
    "    #loss = torch.sum((a2 - y_batch)**2)\n",
    "    \n",
    "    # the function should return the loss and both intermediate activations\n",
    "    return loss.numpy(), a2, a1\n",
    "\n",
    "def backward(a2, a1, X_batch, y_batch, W2):\n",
    "    \"\"\"backward pass in the neural network \"\"\"\n",
    "    # Implement the backward pass by computing\n",
    "    # the derivative of the complete function\n",
    "    # using the chain rule as discussed in the lecture\n",
    "    #print('a2',a2.shape)\n",
    "    #print('a1',a1.shape)\n",
    "    #print('x',X_batch.shape)\n",
    "    #print('y',y_batch.shape)\n",
    "    #print('W2',W2.shape)\n",
    "    \n",
    "    # please use the appropriate loss functions \n",
    "    # YOUR CODE HERE\n",
    "    # W1' = X.T * ( ( (2*(a2-yc)*relu(a2)) * W2.T ) * relu(a1) ) ## use relu(a2) or not??? no neg val can pass through\n",
    "    # b1' = 1 * ( ( (2*(a2-yc)*relu(a2)) * W2.T ) * relu(a1) )\n",
    "    # W2' = a1.T * 2*(a2 - yc)\n",
    "    # v2' = 1 * 2*(a2 - yc)\n",
    "    \n",
    "    dCda2 = []\n",
    "    \n",
    "    # dCostda2\n",
    "    if loss_mode == 'mse':\n",
    "        dCda2  = loss_deriv_mse(a2,y_batch)\n",
    "    else:\n",
    "        dCda2  = loss_deriv_crossentropy(a2,y_batch)\n",
    "        \n",
    "    #dCda2  = 2*(a2 - y_batch) # for W1 and W2\n",
    "    \n",
    "    #da2dm2 = relu_derivative(a2) # for W1 and W2 \n",
    "    #dm2dW2 = a1 # only for W2\n",
    "    #dm2da1 = W2 # only for W1\n",
    "    da1dm1 = relu_derivative(a1) # only for W1\n",
    "    #dm1db1 = 1 # ignore\n",
    "    #dm1dw1 = X_batch # just use X_batch\n",
    "    \n",
    "    # dCdW2 = (W2') = dCda2 * da2dm2 * dm2dW2\n",
    "    # calc in order: dCdW2 = dm2dW2 * (dCda2 * da2dm2)  \n",
    "    # fit dimension: dCdW2 = dm2dW2.T * (dCda2 * da2dm2)\n",
    "   \n",
    "    \n",
    "    # b2' = dm1db1 * dCda2 * da2dm2  # first term is 1*\n",
    "    # b2' = dCda2 * da2dm2 # mean over axis=0\n",
    "    \n",
    "    # dCdW1 = (W1') = dCda2 * da2dm2 * dm2da1 * da1dm1 * dm1dw1\n",
    "    # calc in order: dCdW1 = X_batch * [ ((dCda2 * da2dm2)*dm2da1) * da1dm1 ]\n",
    "    # fit dimension: dCdW1 = X_batch.T * [ ((dCda2 * da2dm2)*dm2da1.T) * da1dm1 ]\n",
    "    \n",
    "    # replace: dCdW2 = a1.T * (dCda2 * da2dm2)\n",
    "    #    dCdb2 = b2' = mean_over_axis0( dCda2 * da2dm2 )\n",
    "    #          dCdW1 = X_batch.T * [ ((dCda2 * da2dm2)*W2.T) * relu_derivative(a1) ]\n",
    "    #    dCdb1 = b1' = mean_over_axis0( ((dCda2 * da2dm2)*W2.T) * relu_derivative(a1) )\n",
    "    \n",
    "    # implementation\n",
    "    #tmp1 = dCda2 \n",
    "    #tmp1 = torch.mul(dCda2,da2dm2) # *relu_deriv element wise mult\n",
    "    tmp2 = torch.mm(dCda2,W2.T)\n",
    "    tmp3 = torch.mul(tmp2, da1dm1) # *relu_deriv element wise mult\n",
    "    \n",
    "    dCdW2 = torch.mm(a1.T,dCda2)\n",
    "    dCdb2 = torch.mean( dCda2, dim=0 )\n",
    "    dCdW1 = torch.mm(X_batch.T, tmp3)\n",
    "    dCdb1 = torch.mean( tmp3, dim=0 )\n",
    "    \n",
    "    # function should return 4 derivatives with respect to\n",
    "    # W1, W2, b1, b2\n",
    "    return dCdW1, dCdW2, dCdb1, dCdb2\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    \"\"\" train procedure \"\"\"\n",
    "    # for simplicity of this execise you don't need to find useful hyperparameter\n",
    "    # I've done this for you already and every test image should work for the\n",
    "    # given very small trainings database and the following parameters.\n",
    "    h = 1500\n",
    "    std = 0.001\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # initialize W1, W2, b1, b2 randomly\n",
    "    # Note: W1, W2 should be scaled by variable std\n",
    "    #W1 =  np.random.normal(0, 1.0,  h * nn_img_size**2).reshape((nn_img_size**2,h))\n",
    "    #W2 =  np.random.normal(0, 1.0,  h * num_classes).reshape((h,num_classes))\n",
    "    #W1 *= 1/(h * nn_img_size**2)\n",
    "    #W2 *= 1/(h * num_classes)\n",
    "    #print(1/(h * nn_img_size**2))\n",
    "    #print(1/(h * num_classes))\n",
    "    \n",
    "    W1 = torch.normal(torch.zeros(nn_img_size**2,h), torch.ones(nn_img_size**2,h))\n",
    "    W2 = torch.normal(torch.zeros(h,num_classes), torch.ones(h,num_classes))\n",
    "    W1 *=std\n",
    "    W2 *=std\n",
    "    # failure in predictions\n",
    "    #W1 *= 1/(h*nn_img_size**2)\n",
    "    #W2 *= 1/(h*num_classes)\n",
    "    \n",
    "    #b1 = np.random.normal(0, 0.2, h)\n",
    "    #b2 = np.random.normal(0, 0.2, num_classes)\n",
    "    b1 = torch.normal(torch.zeros(h), torch.ones(h))\n",
    "    b2 = torch.normal(torch.zeros(num_classes), torch.ones(num_classes))\n",
    "    b1 *=std\n",
    "    b2 *=std\n",
    "    #failure in predictions\n",
    "    #b1 *= 1/h\n",
    "    #b2 *= 1/num_classes\n",
    "    \n",
    "    #print(b1)\n",
    "    #print(b2)\n",
    "    \n",
    "    lenY = y_train.shape[0]\n",
    "    \n",
    "    # run for num_epochs\n",
    "    for i in range(num_epochs):\n",
    "\n",
    "        X_batch = None\n",
    "        y_batch = None\n",
    "\n",
    "        # use only a batch of batch_size of the training images in each run\n",
    "        # sample the batch images randomly from the training set\n",
    "        # YOUR CODE HERE\n",
    "        idx = random.sample(range(0, lenY), batch_size)\n",
    "        X_batch = X_train[idx]\n",
    "        y_batch = y_train[idx]\n",
    "\n",
    "        # forward pass for two-layer neural network using ReLU as activation function\n",
    "        loss, a2, a1 = forward(X_batch, y_batch, W1, W2, b1, b2)\n",
    "\n",
    "        loss_train_hist.append(loss)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "        # backward pass \n",
    "        dCdW1, dCdW2, dCdb1, dCdb2 = backward(a2, a1, X_batch, y_batch, W2)\n",
    "        \n",
    "        #print(\"dCdb2.shape:\", dCdb2.shape, dCdb1.shape)\n",
    "\n",
    "        # depending on the derivatives of W1, and W2 regaring the cost/loss\n",
    "        # we need to adapt the values in the negative direction of the \n",
    "        # gradient decreasing towards the minimum\n",
    "        # we weight the gradient by a learning rate\n",
    "        # YOUR CODE HERE\n",
    "        W1 -= learning_rate * dCdW1\n",
    "        W2 -= learning_rate * dCdW2\n",
    "        b1 -= learning_rate * dCdb1\n",
    "        b2 -= learning_rate * dCdb2\n",
    "        \n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "X_train, y_train = setup_train()\n",
    "W1, W2, b1, b2 = train(X_train, y_train)\n",
    "\n",
    "# predict the test images, load all test images and \n",
    "# run prediction by computing the forward pass\n",
    "test_images = []\n",
    "test_images.append( (cv2.imread('./images/db/test/flower.jpg', cv2.IMREAD_GRAYSCALE), 1) )\n",
    "test_images.append( (cv2.imread('./images/db/test/car.jpg', cv2.IMREAD_GRAYSCALE), 0) )\n",
    "test_images.append( (cv2.imread('./images/db/test/face.jpg', cv2.IMREAD_GRAYSCALE), 2) )\n",
    "\n",
    "for idx,ti in enumerate(test_images):\n",
    "    resized_ti = cv2.resize(ti[0], (nn_img_size, nn_img_size) , interpolation=cv2.INTER_AREA)\n",
    "    X_test = resized_ti.reshape(1,-1)\n",
    "    #print(X_test.shape)\n",
    "    # YOUR CODE HERE \n",
    "    # convert test images to pytorch\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "    # do forward pass depending mse or softmax\n",
    "    # evaluate training set accuracy\n",
    "    #print(X_test.T.size())\n",
    "    #print(W1.size())\n",
    "    hidden_layer = torch.mm(X_test,W1)\n",
    "    #print(hidden_layer.size())\n",
    "    hidden_layer[hidden_layer<0] = 0\n",
    "    a2_test = torch.mm(hidden_layer, W2)\n",
    "    \n",
    "    print(\"Test output (values / pred_id / true_id):\", a2_test, torch.argmax(a2_test), ti[1])\n",
    "    \n",
    "# print(\"------------------------------------\")\n",
    "# print(\"Test model output Weights:\", W1, W2)\n",
    "# print(\"Test model output bias:\", b1, b2)\n",
    "\n",
    "#print(np.asarray(loss_train_hist))\n",
    "\n",
    "plt.title(\"Training Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel('Training Loss '+loss_mode)\n",
    "plt.plot(range(1,num_epochs +1),loss_train_hist,label=\"Train\")\n",
    "plt.ylim((0,5.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 50.0))\n",
    "plt.legend()\n",
    "plt.savefig('simple_nn_train_'+loss_mode+'.png')\n",
    "plt.show()\n",
    "\n",
    "#plt.title(\"Training Loss vs. Number of Training Epochs\")\n",
    "#plt.xlabel(\"Training Epochs\")\n",
    "#plt.ylabel(\"Training Loss Cross\")\n",
    "#plt.plot(range(1,num_epochs +1),loss_cross_train_hist,label=\"Train\")\n",
    "#plt.ylim((0,5.))\n",
    "#plt.xticks(np.arange(1, num_epochs+1, 50.0))\n",
    "#plt.legend()\n",
    "#plt.savefig(\"simple_nn_train_cross.png\")\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
