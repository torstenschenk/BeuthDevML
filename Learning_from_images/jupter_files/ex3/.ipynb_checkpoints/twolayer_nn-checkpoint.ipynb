{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 0.951850\n",
      "iteration 10: loss 0.616917\n",
      "iteration 20: loss 0.474786\n",
      "iteration 30: loss 0.432075\n",
      "iteration 40: loss 0.402280\n",
      "iteration 50: loss 0.643980\n",
      "iteration 60: loss 0.385824\n",
      "iteration 70: loss 0.327317\n",
      "iteration 80: loss 0.342414\n",
      "iteration 90: loss 0.228462\n",
      "iteration 100: loss 0.200502\n",
      "iteration 110: loss 0.288132\n",
      "iteration 120: loss 0.199570\n",
      "iteration 130: loss 0.179198\n",
      "iteration 140: loss 0.164429\n",
      "iteration 150: loss 0.135989\n",
      "iteration 160: loss 0.144444\n",
      "iteration 170: loss 0.082664\n",
      "iteration 180: loss 0.098975\n",
      "iteration 190: loss 0.143793\n",
      "iteration 200: loss 0.129619\n",
      "iteration 210: loss 0.142088\n",
      "iteration 220: loss 0.035081\n",
      "iteration 230: loss 0.107018\n",
      "iteration 240: loss 0.058656\n",
      "iteration 250: loss 0.167636\n",
      "iteration 260: loss 0.060541\n",
      "iteration 270: loss 0.046619\n",
      "iteration 280: loss 0.057880\n",
      "iteration 290: loss 0.091070\n",
      "iteration 300: loss 0.047254\n",
      "iteration 310: loss 0.021826\n",
      "iteration 320: loss 0.094030\n",
      "iteration 330: loss 0.069987\n",
      "iteration 340: loss 0.033855\n",
      "iteration 350: loss 0.035212\n",
      "iteration 360: loss 0.024046\n",
      "iteration 370: loss 0.003685\n",
      "iteration 380: loss 0.076654\n",
      "iteration 390: loss 0.039517\n",
      "iteration 400: loss 0.039914\n",
      "iteration 410: loss 0.034163\n",
      "iteration 420: loss 0.059574\n",
      "iteration 430: loss 0.012669\n",
      "iteration 440: loss 0.026423\n",
      "iteration 450: loss 0.039043\n",
      "iteration 460: loss 0.019857\n",
      "iteration 470: loss 0.022434\n",
      "iteration 480: loss 0.027128\n",
      "iteration 490: loss 0.027734\n",
      "Test output (values / pred_id / true_id): tensor([[0.1399, 0.4679, 0.1291]]) tensor(1) 1\n",
      "Test output (values / pred_id / true_id): tensor([[ 0.9418, -0.5351,  0.6714]]) tensor(0) 0\n",
      "Test output (values / pred_id / true_id): tensor([[0.1559, 0.2501, 0.6115]]) tensor(2) 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5hU1fnA8e+7nWUXlt47SBUQF0RBUWMBa6JGNJaYmBBj7In+NMYSo5F0NZoosSVij72iQUFBepXO0hcWtlB2Wbbv+/vj3pm9szu7zJbZMryf55lnZ24758zMvnPuueecK6qKMcaYyBPV1BkwxhgTHhbgjTEmQlmAN8aYCGUB3hhjIpQFeGOMiVAW4I0xJkJZgA8zEYkWkcMi0rshtzWNS0RmisiDTZS2iMh/ROSgiHzTCOn9VkSebOhtmzsRGSIipU2dj4ZkAb4SN8D6HuUiUuB5fVVtj6eqZaqapKo7G3Lb2hKRh0XkxYY+blMRkXQRyRCRRM+yG0Tkf02ZrzA5HZgEdFfVU7wrROQ+z/ezUETKPK9X1SUxVX1AVW9q6G1rQ0QSRERFJL/S/+QtDZ1WJLMAX4kbYJNUNQnYCVzoWfZy5e1FJKbxc2lccUCDB5dwE5HoWu7SB9imqkcqr1DV33m+rzcBX3u+r6OCpN3Svq+Dvf+TqvpEU2eoJbEAX0tuTfh1EXlVRPKAq0XkZBFZ6J5CZ4jIEyIS624f49ZE+rqvZ7rrPxGRPBFZICL9arutu36KiGwSkUMi8ncRmS8i19WhTMNFZK6b/29F5HzPugtEZL2bfrqI3O4u7ywiH7v77BeRr6o59rMiMr3Sso98NTER+bWI7BGRXBHZICKn1yLrfwTuEpE2QdIdKCJaadk83/sjIj9xy/yEW4Y0ETlJRK4XkV0isk9Erq502E4iMtt9L74UkV6eYw8Tkf+578UGEbnUs26miDwlIp+KSD5wapD89hSRD939N4vIj93l04CngVPdGux9tXh/vDXhn4vIFmCNu/yf7ueZKyKLRWS8Z5/pIvKs+3yIiJSKyI/c7bNE5M46bpskIq+47/caEblHRNJqU55K6b4qIm+5n8cSERnuWX+8iHztprVaRKZ41rV2P/dd7v/OXPH88NWQ/wkissJ9z/aKyKN1yXujUlV7VPMAtgNnVVr2MFAMXIjzA9kKGAucBMQA/YFNwE3u9jGAAn3d1zOBbCAViAVeB2bWYdvOQB5wsbvuDqAEuK6asjwMvBhkeRywDbjLPc5ZwGFgoLs+CzjFfd4eGOM+/xPwpLtPHDCpmnTPdN9HcV93AAqALsBwYAfQ1V3XD+gf4meTjtN08T7woLvsBuB/7vOBztc7YJ95vvcH+AlQClwDRAPT3bw8AcQD5wGHgETPZ3EImOCufwqY465LBnYD17qf4YlADk7t07fvAeBk9zsTH6Q884G/AwnAGPdzn+TJ65wQ3pMq27nHU+AjIAVo5S6/Fmjnfn73AruAWHfddOBZ9/kQd/+n3GONxfn+96/Dto8BnwNtcc5K1gFp1ZTFl++e1ayf7h77IrcMvwE2up9lgvtZ/tJddy7Od7qfu+9zwGdAV3f7U92/R8v/CuD7ns/8pKaOUUd7WA2+buap6geqWq6qBaq6RFUXqWqpqm4FZuC0mVbnv6q6VFVLgJeB0XXY9gJgpaq+5677G05QqK0JOAH6T6paoqr/Az4BrnDXlwDDRCRZVfer6nLP8u5Ab1UtVtW51Rx/Ds4/2cnu68txmhH24QTYBGC4iMSo6jb3/auN+4DbRKRDLfcD2KyqL6lqGc6PZ2/gt6papKofu9v092z/garOV9Ui4NfAaSLSDSfIbFLV/7jfgWXAu8Blnn3fUdUF7nemyJsJcc7KxgF3q2qh+x6/gPPj01AeUdWDqloA4Ob1gPvd+T3OD2//GvZ/wM3bEmADMLIO214OPKyqh1R1B/CPEPK91q2F+x7e/6tvVPV9twzTgY44P46+M6S/ut/pWTg/LFPFObO+FrhZVfeqc93ra/c7cLT8lwDHiUgHVc1T1UUh5L9JWYCvm13eF+6p6UfuaVsu8BDOl606ez3PjwBJddi2uzcf6lQr0kPIe2XdgZ3u/j47gB7u8+/hBLCdIjJHRE5yl/tqvLNFZIv3VNZLVctxgueV7qIf4PxQoaobcWpZDwGZ7il319pkXlVXAbNwzkBqa5/neQFQpqo5lZZ5Pxvv+30Ip0bfHac2OsEbiICpQLdg+wbRHchW1XzPMu9n0BAqf2fvEZGNInII5+wigeq/s2Wq6q081PSdDbqtiAjOWZs3HzW9Jz7DVTXF8/BWJLyfRymwB+e9rOk73Q3nLKu6ikRNZf0hTrDfJCKLROTcEPLfpCzA103lKTifwWnbHKiqbYD7AQlzHjKAnr4X7j9QXQLCHqCXu79Pb5wmB9wzk4twmoQ+BF5zl+eq6u2q2hf4LvB/lWpXXq8Cl7s11THAO74VqjpTVSfgNM9EA3Vp17wf+DnOKbdPPoB4etlUWl8X3jb3tjhNDXtwAs3sSoEoSQN7l9Q0beseoKOItPYs838GDcSfvoicDdyM8+OdgtP0VkAYv7NusM3E853F837WkffziMYJ7HvcR+Wuxr73MwPnzLGms5WgVHW9qk7F+V94AnhbROLqlvXGYQG+YSTj1ObyRWQo8LNGSPNDYIyIXOheILoV6HSUfaLdi26+RzzwDc4X/pciEisiZ+K0P78hIq1E5Aci0sY9Dc4DygDcdAe4PwyH3OVlwRJ1T3UP4TRdfayque4xhorIGW4+CtxH0GPUxD0TeAsnaPnsdR9XizO+YBpOTbs+LhTngno8zjWNeaqagXMdYLj7XsW6j3EiMjjE/G8DlgK/F5F4ERkN/Aj3TCcMknGaG7JwmucewqnBh9sbwL0i0lacsR4/r+fxThGnE0AszhlcDrAc+BqIEpHbxOm4cDZwDvCm+z3+D/C4iHRxvxsTJYSeTSJyrds8U4bzfVagvJ5lCCsL8A3jlzinb3k4tfnXw52g24Y9Ffgrzhd7AM5FoKIadruaikBaAGx024MvxLlYm41TM/mBqm5y9/khsMNterqeinbhwcAXOBev5gOPq+q8GtJ+FecC7iueZfE4PWGycYJxO5yLZYjID6V2/bh/i6fZwK0x/hSnrTwb56JrfdtMZ+IE9mycU/Vr3LQO4VzIuxqnhrgX50wkvhbHngoMcvf9L/BrVf2ynvmtzgfAV8AWnKaKbJxgH26/wWkO2oFznecNav6+AmyUwH7wf/Csewv4sXvMS4FL3Tb1QpxrVJfh/G/8FZiqqlvc/W7BKfsKd/3vCO3s5QI3P3k4n+/lbtNQs+Xr2WBaOLcGsge4TFW/bur8GHM04nS5nayqtW7LFqfrbUdV/UnD5yxyWA2+BRORye7pbjxOb5JSYHETZ8uYoESkl4iMF5Eot8/6rXiux5iGF9ZRbSKynYp221JVTQ1nesegiTjttHHAWuC7lbvgGdOMxAPP41wLOYDT5PVsk+YowoW1icYN8KmVuh0ZY4xpBNZEY4wxESrcNfhtOKdiCjyjqjOCbDMNmAbQunXrE4cMGRK2/BhjTKRZtmxZtqoG7SId7gDfXVX3iEhnnKHCN6tq0EmpAFJTU3Xp0qVhy48xxkQaEVlW3fXNsDbRqOoe928mztXyceFMzxhjTIWwBXhxpuRM9j3HGUm2JlzpGWOMCRTObpJdgHfcKU5igFdU9dMwpmeMMcYjbAHenfa1yh1ljDGmIZSUlJCenk5hYWFTZ6VRJCQk0LNnT2JjY0Pep6XdvssYYwBIT08nOTmZvn37EjgZauRRVXJyckhPT6dfv35H38Fl/eCNMS1SYWEhHTp0iPjgDiAidOjQodZnKxbgjTEt1rEQ3H3qUlYL8MYYE6EswBtjTB3k5OQwevRoRo8eTdeuXenRo4f/dXFxcUjH+NGPfsTGjRvDlke7yGqMMXXQoUMHVq5cCcCDDz5IUlISv/rVrwK2UVVUlaio4HXpF154Iax5tBq8McY0oLS0NEaMGMENN9zAmDFjyMjIYNq0aaSmpjJ8+HAeeugh/7YTJ05k5cqVlJaWkpKSwt13382oUaM4+eSTyczMrHderAZvjGnxfvvBWtbtyW3QYw7r3oYHLhxep33XrVvHCy+8wNNPPw3A9OnTad++PaWlpZxxxhlcdtllDBs2LGCfQ4cOMWnSJKZPn84dd9zB888/z913312vMlgN3hhjGtiAAQMYO3as//Wrr77KmDFjGDNmDOvXr2fdunVV9mnVqhVTpkwB4MQTT2T79u31zofV4I0xLV5da9rh0rp1a//zzZs38/jjj7N48WJSUlK4+uqrg/Znj4uL8z+Pjo6mtLT+9/O2GrwxxoRRbm4uycnJtGnThoyMDGbNmtVoaVsN3hhjwmjMmDEMGzaMESNG0L9/fyZMmNBoaYf1hh+1ZTf8MMaEav369QwdOrSps9GogpW5yW74YYwxpulYgDfGmAhlAd4Y02I1pybmcKtLWS3AG2NapISEBHJyco6JIO+bDz4hIaFW+1kvGmNMi9SzZ0/S09PJyspq6qw0Ct8dnWrDArwxpkWKjY2t1d2NjkXWRGOMMRHKArwxxkQoC/DGGBOhLMAbY0yEsgBvjDERygK8McZEKAvwxhgToSzAG2NMhLIAb4wxEcoCvDHGRCgL8MYYE6EswBtjTISyAG+MMRHKArwxxkQoC/DGGBOhLMAbY0yECnuAF5FoEVkhIh+GOy1jjDEVGqMGfyuwvhHSMcYY4xHWAC8iPYHzgWfDmY4xxpiqwl2Dfwy4CyivbgMRmSYiS0Vk6bFy81xjjGkMYQvwInIBkKmqy2raTlVnqGqqqqZ26tQpXNkxxphjTjhr8BOAi0RkO/AacKaIzAxjesYYYzzCFuBV9R5V7amqfYErgC9U9epwpWeMMSaQ9YM3xpgIFdMYiajqHGBOY6RljDHGYTV4Y4yJUBbgjTEmQlmAN8aYCGUB3hhjIpQFeGOMiVAW4I0xJkJZgDfGmAhlAd4YYyKUBXhjjIlQFuCNMSZCWYA3xpgIZQHeGGMilAV4Y4yJUBbgjTEmQlmAN8aYCGUB3hhjItRRA7yIdBKRZ0TkQ/f1MBG5Luw5M8YYUy+h1OBfBOYCvdzXm4FfhitDxhhjGkYoAb6zqr4ClAOoaglQFtZcGWOMqbdQAny+iLQHFEBExgJ5Yc2VMcaYegvlptu/Aj4A+ovIXKAHcFlYc2WMMabejhrgVXWpiJwBDAUEWKeqxWHPmTHGmHoJpRfNJUC8qq4CJgMzRWR02HNmjDGmXkJpg39QVfNE5BTgQuB14OnwZssYY0x9hRLgfT1mLgD+oapvAfHhy5IxxpiGEMpF1gwReQqneSZVROKwEbDGGNPshRKoL8cZ6HS+qh4AOgJ3hzVXxhhj6u2oAV5VDwOfAlEiMhInwO8Od8aMMcbUz1GbaETkAWAasA13sJP797Qw5ssYY0w9hdIG/wOgv6oWhTszxhhjGk4obfBrgeRwZ8QYY0zDCqUG/wiwQkRWA/5avKpeErZcGWOMqbdQAvy/gb8B3+LOKGmMMab5CyXA71fVv4Y9J8YYYxpUKAF+iYj8DnifwCaa1TXtJCIJwFc4o15jgP+q6gP1yKsxxphaCCXAj3P/nu5ZFko3ySLgTFU9LCKxwDwR+URVF9Y+m8YYY2orlOmCT63LgVVVgcPuy1j3odXvYYwxpiGFdU4ZEYkWkZVAJvC5qi4Kss00EVkqIkuzsrLCmR1jjDmmhDXAq2qZqo4GegLjRGREkG1mqGqqqqZ26tQpnNkxxphjSqPMCqmqB4E5ODNSGmOMaQQh3dFJRJLd53eLyBuh3NFJRDqJSIr7vBVwFrChvhk2xhgTmnDe0akb8KU7AnYJThv8h3XPqjHGmNoIpZtklTs6ichvjraT20/+hPpkzhhjTN3ZHZ2MMSZC2R2djDEmQoVSg+8IvKeqRSIyERgJzAxvtowxxtRXKDX4d4FyERkA/AcYCrwS1lwZY4ypt1ACfLmqlgCXAI+p6s1Aj/BmyxhjTH2FEuBLReT7wDWAr5tjbPiyZIwxpiGEEuB/DJwB/FFVt4pIP+DV8GbLGGNMfYUym+QaEbkFGCgiQ4A0VX0k/FkzxhhTH0cN8CJyKvASsBsQoKuIXKOq88OdOWOMMXUXSjfJvwHnqeo6ABEZihPwU8OZMWOMMfUTSht8nC+4A6jqeiAufFkyxhjTEEKpwS8XkWdwau0AVwErwpclY4wxDSGUAH8DcAtwF04b/FfAE+HMlDHGmPoLpRdNIfBH9wGAiLyMU5M3xhjTTNV1Vsg63YjbGGNM47Fpf40xJkJV20QjIiOrW4VNVWCMMc1eTW3wT9WwLq2hM2KMMaZhVRvgVdXa2Y0xpgWzNnhjjIlQFuCNMSZCWYA3xpgIFcpsksF60xwCdqlqecNnyRhjTEMIZaqC54DRwFqcLpJDgTVAWxGZpqqzw5g/Y4wxdRRKE81m4ERVHa2qo4ATgZXAucBfwpk5Y4wxdRdKgB+qqqt9L1T1W2CMqlpfeGOMacZCaaLZIiJ/B15zX08F0kQkHigNW86MMcbUSyg1+GuBdOBu4B5gD/BDnOD+nfBlzRhjTH2EMl3wEeAP7qOyQw2eI2OMMQ0ilG6S44EHgD7e7VX1uDDmyxhjTD2F0gb/As7dnJYBZeHNjjHGmIYSSoDPVdUPwp4TY4wxDSqUAP+FiDwKvA0U+RZ6u04aY4xpfkIJ8BMr/QVQ4LSGz44xxpiGEkovGpsX3hhjWqCabtl3paq+KiK3BFuvqk/UdGAR6QX8B+gKlAMzVPXx+mTWGGNM6Gqqwbdz/3aq47FLgV+q6nIRSQaWicjnqrqujsczxhhTCzXdsu8f7t/76nJgVc0AMtzneSKyHugBWIA3xphGEMpAp47Aj4G+BA50mhZqIiLSFzgBWBRk3TRgGkDv3r1DPaQxxpijCKUXzXvAQmAedRjoJCJJwFvAbaqaW3m9qs4AZgCkpqZqbY9vjDEmuFACfGtV/WVdDi4isTjB/WVVfbsuxzDGGFM3ocwm+YmInFPbA4uI4NwNar2q/rXWOTPGGFMvoQT4G4BPReSwiOwXkQMisj+E/SYA1wBnishK93FevXJrjDEmZKE00XSsy4FVdR7OPVyNMcY0gZoGOg1S1c3A8Go2sblojDGmGaupBn83cD3wVJB1NheNMcY0czUNdLre/Wtz0RhjTAsUShs8IjIEGAYk+Jap6ivhypQxxpj6C2Uk62+Ac4AhwCzgXJxBTxbgjTGmGQulm+RU4AwgQ1WvAUYRYs3fGGNM0wklwBeoahlQ6s4KuRfoH95sGWOMqa9QauIrRCQFeB5YCuQCy8OaK2OMMfVWY4B3pxt4UFUPAk+JyCygjapagDfGmGauxiYaVVXgQ8/rNAvuxhjTMoTSBr9YRMaEPSfGGGMaVE1TFcSoaikwEfipiGwB8nHml1FVtaBvjDHNWE1t8IuBMcB3GykvxhhjGlBNAV4AVHVLI+XFGGNMA6opwHcSkTuqW2k38TDGmOatpgAfDSRhc7obY0yLVFOAz1DVhxotJ8YYYxpUTd0kreZujDEtWE0B/juNlgtjjDENrtoAr6qh3FjbGGNMMxXKSNYW46WFOzjl0dlNnQ1jjGkWImpe9/veXQOAquLMk2aMMceuiKrB+xSXlTd1FowxpslFZIAvKdOmzoIxxjS5iAzwxaVWgzfGmIgM8CXWRGOMMZEZ4K0Gb4wxkRrgrQZvjDGRGeALS8ootSBvjDnGRVQ/eJ/zn5gHwPbp5zdxTowxpulEZA3eGGPMMRLgVZX8otKmzoYxxjSqYyLA//2LNIY/MIsD+cVNnRVjjGk0x0SAf3fFbgByLMAbY44hYQvwIvK8iGSKyJpwpeGlWv30BL41Nv+YMeZYEs4a/IvA5DAeP0BRDYObfMHf4rsx5lgStgCvql8BjXbTkKKSGgJ8Y2XCGGOakSZvgxeRaSKyVESWZmVl1fk4haVl1a7ztd6UlVuoN8YcO5p8oJOqzgBmAKSmptYpAn+0OoPyIG3wvht/qFuHLw0xwB/ILyY2Joqk+CZ/e4wxps4iIoL96s1VDOqSVGV5abkSGy2Uu603odbgT/jd57RLjGXF/ec0ZDaNMaZRNXkTTUOIi4li1/4jVZaXVrrxR0lZOX/7fBMrdh446jEPHClpsPwZY0xTCGc3yVeBBcBgEUkXkevDlVZ8TFTQgOybVdLXi6asXHl89ma+949vwpUVY4xpNsLWRKOqV4br2JXFxTi/U/ExUZSr+m/Z55tR0lePt2mEjTHHkohpogHo0iaBmKiKIvkuqvouwNbUV94YYyJNZAT4aKcYHZPiAkar+u7s5OtgU1RSfVdKY4yJNBER4OPdGnzr+BiioyoivK8G72uiKaxhMNTRLNqaw77cwjrvb4wxjS1CAnw0AAmx0f5gD542eF8NvobBUEczdcZCLvz7vLpn0hhjGllEBHhfG7wT4KP9yyv3oqmuBv/yoh3+qYSD9ZX37Z+ZV+RftvtgQQPk3BhjwieiAnyr2KhKNfjKTTRVa/Cb9+Vx7ztruOW1FYDTV76yyhdnl+3Yz4TpX5CWebghsm+MMWERGQE+2lODj62owZeEUIP3tdP72te9XSl9+1f+Ycg45GxrtXhjTHMWEQE+PtZXg4/21+YBSsqUrVmH/YOgvG3wvqYY30XZUn/f+YomGl9g9/4wPPTBOo4UO8tzC2y0qzGm+YqIAB/r1uDjK19kLS/nzL/M9b/2Bur8Yucerb5auq8m722i8W3vrcE/P3+b//UhC/DGmGYsIgK8r5dMq0oBvnJ7undKYd9NuCuPei0u9Qb4sir7Af4a/MyFOzj+gVlB2+2NMaapRUSA941UTYiNCuhF85fPNgVs562JH3SbbXwBfc+hQpbtOBAQrH1NOpXb7n0BfsPePPKKSjlwxO71aoxpfiIqwLeKjfa3xwOs3ZMbsJ23N0zOYScoe2vsl/7zG3+NHioCe0FxYA2+wG3e8ckvshGyxpjmJyLmg/d1XY+v1E2yMu9UBTn5Rdz++kqOVArWgW3wwZto/vX1toDXdrHVGNMcRVQNPjoqirOGdglY17ZVrP+5t6klK6+Id1bsZtbafQHbewP8R99mkJlXeNQ5bPIKS2tcb4wxTSEyAryvy6MI5x3fjc9vP82/7o+XjfQ/97bBP/zR+qDH8jbRvDB/O4/9b/NR57DJLbQavDGm+YmMAO/W4H3zjHVKjgec2SV7tmvl3y6U6YIr94iZuzEr6AhYrzwL8MaYZiii2uDFnSs4JTGOp68ew8n9OwbUro8WqKFqgN99sIA1ew7VuE9uQSlvLt3FuH7t6dOhdS1zX3fnP/E1pWXKLM8ZizHG+EREDd43VUFsdMVUwZNHdKNtYiyJcRXdJn0XS88eFthO71VSVnWysU/X7AuyZYV9uYXc+d/VTPrTnIDRstuz8/3TJBzN1qzDfPxtRtB1O3OOMOz+T9m8Ly9g+do9uWystKw23lu5O6T70xpjWqaICPC/vXg4Pz21H5OO61RlXfvWcdx0xkCg4iLrXecOrvZYP/3P0oDX0VFC9uGiarZ2bM+puOH39mzn+a79Rzj9z3Oq9MWvznPztnH76yuD/iBsz8nnSHEZ3+6u+Uyitm59baXdn9aYCBYRAb5jUjz3nj+MmOiqxRERfnXuYNolxvqbaIJt563pe/Vpn3jU9P+3vqKGP/2T9RwuKvUPpHp+fmCXypkLd/Dg+2urHCP9QAFFpeUUBGlG8nXlzDhUyKKtOaxOPxjQ3HS4qPa9eIJNi2yMiSwREeBDER0VRZFbg4+JEt6/aQI3TBrgX//ghcOD7jegc1KQYwlXndQ76PZfbszixy8s8U8/fKS4LKBW/pt31/DiN9v577J0Dh2puD6wx52Z8soZC7n86QUBxzzsDqTKOFTA1BkLuejJ+WR55qbPrMOdpg56Rt/WNNXCwq05zE/LrvXxjTFN75gJ8LHR4p8KOCZaGNkzhdvOGuRff7Ag+HQDAzoFBvhbvjOITQ9P4fzjuwFw8ejuVfZZvH0/27Lz/a+3us+9gf5Xb65i8uNfkZlbiKr6A/yq9EMs3r4/4Hj+GvzBikDuvfnI3joE+P35FeXdtf9ItdtdMWMhVz27qNbHN8Y0vWMmwHvv1ep77h31evrgzkH369Y2IeD1gE6tiY4S2rgDqHq1C2zCadsqNuDG3wB3vLGK0rLygFo3OE0up/95Dl9uzCS/0nQI3ikUfFMh7PQE4oxDFXPR7z1UvwCfcaiQnTlHquSvMptUzZiW5ZgJ8N4+8LFRTrHFE4mP65LM9unn86MJfQG46qTe9OmQSIekuIDjRLn7+EbIto6v6Gm68v6zWXDPmbxz4wTP9rBq10EuenI+X212mjquO6UvK+47G3CacH78YuCFXQgM4L4a/GbPHaRWp1dccN2aVXG2ECpvgN+fX8xpf/qSCdO/qHb7LzdmMujeT1h7lC6jxpjm45gJ8N7aaXS0VLvdfecPY9lvzuKR7x3P3DvP8Ad0H9/LjknxtEuMpV/Hin7vKYlxJMbF0CahIugvvOc7AKzLyOX3HzujZy9P7UW71oE/HJXN+Gqr/5aAwS6iLttxgOgooX/H1mzydJVcsCWHtMzD1XbP/OtnG5mflk2OJ8D72uOLK9XQvceYtWavP11jTMtwzAR4L18NPpioKKFDUrz/dWrfdsTFRPlHx/oCfqu4aJbfdzaTR3RlcJfkgGMkJ1TMf9OudRyjeqUAFTcISXZ/AJ648oRq8/Hyop387sN1ABwJMlvl8p0H6JgUx3Fdkv0/BEWlZVz5r4VMefwrxj86mz/P2hiwj6ryxBdpXPXsooAafPqB4Lce/O0H6/zPfQPGjtb7RlX9c+sbY5rWMRPgf3FGRY8Zb3v80XROTmDTw1MY09sJ0t49fU087900gVX3n+NfnuypwcdGR/HqT09iYOckf3D0rb9oVHcuO7EnEHg9YGpqL6BiCoT84qo1eFUnb8d1SWJ7Tj6FJWV8k5YDOIO19uUW8eSXaQG1/9yCiueZeYWkJMaSnBDDhr1VB0sVFJfx4jfbq+xbXYC//OkFvL08nca0b/IAABeDSURBVIc/Ws/Aez/xzw9kjGk6x0yAv/PcIf7nMbUI8D4TBnYEoH+nqt0mE2KjaZsYG/DaKzEuhhHd2/hfe9vtfRdxu7RJ8Af5C0d153sn9CAt8zBXzFjA7PWZAc0+FfvEM7BLMuUK27LzeWnhjip52+2pnWfnVzRT7cstoktyAu1bx7Fhb26V/dIPBPas8dXgS4ME7vyiUhZv388db6ziuXlOv/9dB6rvmWOMaRzHTID3iqpDgL9mfB8W//o7DO6afPSNg+jtDpiKjRb/PWQB/2Ro3VMSOH+k0/UyKSGGHimtyC0sZeHW/RSUlPn7408Y2IEeKc4+ndwaPMD8tGy+2JBJ3w6BvXp8XSjfWZHO60t2+Zd/vm4fndvEk5IYx77cisDf9+6PeHruloAeO1DRgyevsIQtWYe5+tlF/q6d3i6b3d0fn7eWpXPHGyu5+Kn5vL08Peh7UlBcFnAxuTkpLSsnM6/2vZOMaU4iYrKx+vjw5okB88dUR0To3CbhqNtVp5sblCvPdXPRqB60SYjlpP4dSIyLZtJxnRjVs22Vi5ntE+P4/PbT6NU+kcufcQZCpfZpR7+OTrfNd1bsBuDq8X0CpkL+Nv0g5eXK7a+vqpKnLm0SiImq2jXyL59t5NfnDQ1Y5huZm1tQyg0vLWNz5mHeXbmbn08aEDDQqlObBPYcKuSJL9L8yx7MOswlY5ymqLmbsnh6zhYWbcthwsCOfL05m6vH9+be84bRqprRxMGUlysb9+UxpGuyv6lMVQN6RtXHVc8uYtG2/Wz9/XmUq7Ivr8j/w2pMS3FM1uC9RvRoy4l92oc9na5tg/84tIqLZsrx3WjfOo6E2GguHt0DEWFoN+dMwXey0b51HIO6JJMQG809U4Zyy5kDuWRMD+JjohnXt73/9oRT3AFYPn/+bBM/enFJ0LQLisuqDOQCiI+JZkfOERLjopl75+ncNbli7p6XFu7wd9ecvT6T856Yx89fXu5fn+e5u9WEgR0A6O4JjD98fjELtuZQrvC122105sKdvLms4uwiM7eQlxZsZ9bavWTmFQYdSTt7QyZTHv+aJ79Io7i0nMKSMvrd8zHPzN0StKzBlJUr763cXaV/f1ZeEYu2OYPNLnpqHr//eANn/WVulbt/GdPcHfM1+HB55poTAy7IVh4wdTSnDOjIivvO5o+zNvLq4p1cMa5iaoSTB3Tg5AEd/K/vnDyYS9xJw3qktKJrmwSyDxcFtJcP7Jzk720zNbUXry/dRc92rTh1UCeenRc4X058TBS79h+hd/tE+nRoTb8gUyBfOKo7H6zaU2X5Vs8I3gtHdqdfx9Z8sCr4LJle97/nzM8zeURXxv1+dpX1n91+Gou25lBarlx3Sl82ZDg/aC98s52/fL7J3zT16CcbuH5iP/98QxmHCujaJiGgZp9bWEKbhFg+XL2HW19byZHiMq70vL/fbKn4QVmzO5c1u520tmblM6JH26OWpSks2b6fDXvzuGZ8n6bOimlGLMCHybnDuwa87tam9qf37VrH8X+TB3Pu8C6c2KddtduN6d2Ox6aO9k9ANqBza8pUKSwuI8/tRTN5eFeezEyjdVw0f7hsJN9P7cmIHm2JEuGcYV24cFR3bn7VmT+nqLScnfuP+Pv4Vz77uOXMgVw/sT8rdx1g1/6KNvQBnVqzJSufUwd1ZO+hQr4ztAs5+cUcKijhSHEpiXFVv263fmcQfTsmcvvrq7j/vbXsORi83fu1xbv8E7fNT8vmf+szgYoBW94ZPY9/8DPG9WtPQmwUs9bu47azBnHbWcdRVq589G0Gt762gl9PGeoP5G8tSw8I8Au3Bk4V4ZOWeZjh3dtwqKCElERnHMPugwWUlyuZeYUM6JTEU1+mMbx7W84a1oXt2fn8Z8F2Hr1kZK16btXF9935iy44vttRx1g0FlWlqLS8SqcD03iOqQD/9V1nNFnvjjat6vZWpyTGVTuNgtd3T+jhf37tyX3ZmXOEK0/qzYgHZgFw0ejudGkT72/CSe1b0Sw149pUAHq1T+S3H6xlxc6DbM487J9+2dvEcuPpA7jjHKfJ5qs7z2Dxtv1MnbGQIV2TOWVAR7ZkbeOEXinccb2zja/des7GLKaMCPzRAxjevQ2nD+7Moq37eW3JLp6uponFOyunL7gH0zoumvziMuZuyvIve+x/mzllQEeufm6RfwqIR9xBZx2T4lm64wBzN2XRvW0CAzol8eWGTAZ3SfbPtS/idI/dsDePXV+k8ZfPN7H8vrNJjIsOGP07tFsb1rtnFpeO6cmibTmkHyjgRxP6kZwQw5cbMvnBSX0Cgn1BcRn5xaX89D9LufOcwZzi9tZasCWHVnHRjO6Vwo0vL6OsXLlmfF9ueW0Fr08bz6AuwS/2n/C7z7libC+mXzoy6PqG5r3ukX24iAP5xf68vbJ4J/e+s4aXrh/HxIEdEREKS8rIyS+26xmN5JgK8L3aJ9IrhOl/w0FEGNwlmUmDq85Z39Aqnz2A04vnuGqCgs/oXik8ccUJnPrHLwGnNw84QdDnrskV3U1FhHH92vPCdWMZ16+9/4YlBz3t8CN6tCUuOoobX17OSf0Cr3V88ctJ9O3QmqgoYfqlI1mdfoh1GbmcMbgTivOjcP3EfhSUlPHKop30SGnlTMzmzr3TtU1ClYnWvp/aK6D/vo/vwjTAJSf04G33ovRfLh/Fj19cwg+fXxyw/W1nDeLut78F4LIxPdmanR/w47Nk+35+9tKygH18wb1dYixzN2X6Zy+duymLVxfvZEfOEd5buYf1GbmM7p3CzycN5Oczl/nPsmat3cu4fu155OP1vDDfKcPmR6bw8bfOKOJ1Gbnszy/m7L99xXnHd+XJK8cQFSVszw6cquK1Jbt4+LsjKCwt54nZm7lmfB9mLtrBvM3ZXDKmJ3sOFjB1bC/muu9v5V5lxaXl/Pqdb/nRhL4M7161SSr7cBG7DxRwfI+2/N9bq1myfT8vXX8Sj3y0nk/X7uWpH4zh/JHdeHnhTgCueW4xI3u25U+XjeKpL9N4f9UePrhpIuWq/kGAtbXnYAE3zFzGY1NHs+dgIekHjtC5TTwDOiX576p26EhJQPdlrx05+XROTqjVhf2WKKwBXkQmA48D0cCzqjo9nOk1d01xa70bJg3gg1V7Qj5N7tU+kcW//g6/eGU5F7jdNqOjhOO6JHHByKozZ4oIZwxxzjAuGt2dDXvzmHZaf//6gZ2TePvGU7jg7/P8Fy4BUhJjq4wpGNg5iXUZuaT2bc/Zw7owZ2MW3zuhByt2HQSgb8dEurdtxZvL0hnTO4UZ16Yy+bGv/TdkiY2WoD/gEwd2ZF5aNoM6J9G5TTy/uWAY89KyOXd4VyYd14k3bziZzNwi5m7KYs7GTMb2bc/Fo3v4A/yfvj+KQwUl/PaDtby93PlhmP7JhqDv34gebfjhyX2587+r/cumf7KBVrHRtEuMZfnOA5wzrCufrt3LfHdgms+/F+xg9obMgJHFg+79xP98134nqIrAx9/uZUbPrRQUl/H47M0AvHT9ON5ZsZu3l+9m/KNf+N+XvMISXl3sXMReu8cZnfyc57rL2yt2U1xaxti+7RnYOcnfC+vdFbv54OaJfLQ6g8Xb9rM9J59/XZvK7W+sZGtWPg9/dwRvLkv3H883C+ofPt3AiB5t8A4YX51+iEv+Md8/qd6FT84D4IXrxjKqVwrt3WYlVeVv/9tM97YJTB3bCxFBVZn+6QbmbsziyR+cwMDOybz4zXZWpx/iX19v48NVe/w/kp2T43nnFxOYtzmLe97+lndunMCoXikBTYR7DhYw6U9zGNu3He0S47h6fB9OO64TG/bm8u6KPfzk1H60io0mLfOwf4qTs4Z1IbewhPT9BSQnxLBpXx4TB3UkPiaaotIydu0vYKBnavEtWYdZtuMAn67ZS7e2CVwypiet46PJOFjIqYM6svtgASt2HuSUgR3onFz33nlHI6HeUq7WBxaJBjYBZwPpwBLgSlVdV90+qampunRp1Ym3TMvnmy/nkY/W079Ta64Y27vKmIKXFmznvvfW8vx1qZw5pOK2irv2H+HUP37JKz89idyCEm6YuZwbTx/AXZOHsD+/mMXb9rMl6zDj+7cn+3AxP3tpGXeeO5j5adkkxcdw21nH8cD7a/jHVSf6p5woK9ejtovP3ZRF7/aJ/msRB48UM+Z3n/vvAXzhqO5MGdGVGz29iB753gguHdOTO/+7ml37j5CcEMPO/Ud46OIRdGgdhyoc37Mtby7dxT/mbKFD6zhOHtCBj1ZnBFygBjhjcCfWZeQGjFP45NZT6dmuFcc/+FnAtg9dPJxrxvfh/VXOhWOAM4d05osNgc1Zo3qlsMr9wfRpFRvNkG7JrNgZuDxUsdFCablSn1AyYWAH+nRozdyNWex2x1f06ZDIxaN7MD8t299tOCUxlqlje/Gvr7YSbLB0UnwM0VFCflEppeXKcV2S6JycwLy0bE4f3InvDO3Ceyt2s7RSN+QbJg1g1tq9bMvO9zfzeY3ulcKWrMPkFVb0pOrSJp6YqChyC0rIKyplXL/2LNm+n/aJcQFzPR3NtSf3oUdKK37muT9FbYjIMlVNDboujAH+ZOBBVT3XfX0PgKo+Wt0+FuCPbarKsh0HAq4PBNvm3ZW7OXtYV5Liq56AqipzNmVx2qBOYbmwqaq8t3IPBSVlXDG2F1l5RYz7/WxeuG4sCJx+XKc69cWfn5bNP+akMbJnCp+ucQLNqvvPoW1iLIeOlPD+6j28v3I3r087mago4a1l6WQfLmLCwI6s3HWQq07qjYiwYW8ukx/7mivH9ebRS47nuXnb+N2H67julL7cPWUICbHRPPDeGt5Yms6fvz+K3QePcMmYnnRMimfj3jxeX7KLotIyRvdKoXObBP48ayM3nzmQsnJl0bb9vLJ4J7edNYhBnZO5+dXlHN+jLXdPGcql/3R6cf3stP48P38bSfEx9GjXirsnD2XTvjw+XbuXkrJy2iTE8uBFw0nLPMzJAzrw6Zq9bMjI5ZXFOykoKUPVubvaFWN7M3PRDv81kwkDO/DId4/n8mcWkJlXxKiebTl/ZDf+8OlGuqck8IdLRpKWdZiBnZK4/t9LaZcYy/gBHXh7+W5ECPjxSU6IYdqp/Uk/UMCVJ/Xmxy8u8V+sv3RMT1bsOhAwQ2vHpHgKS8r8036M6pXCRaO6s2BLNl9tzg6Y2ttn4sCOnNinnf/s6sbTB/DlxiziooW1e3K5enwf5m7KYlt2PjFRQrvWcSy596xaf2+g6QL8ZcBkVf2J+/oa4CRVvanSdtOAae7LwUDgDFmh6wg0xa2HmirdpkzbynxspG1lbhn6qGrQi3vhbIMPVo2p8muiqjOAGfVOTGRpdb9i4dRU6TZl2lbmYyNtK3PLF86RrOlAL8/rnkDVkTHGGGPCIpwBfgkwSET6iUgccAXwfhjTM8YY4xG2JhpVLRWRm4BZON0kn1fVteFKjwZo5mlh6TZl2lbmYyNtK3MLF7aLrMYYY5rWMT+bpDHGRCoL8MYYE6FafIAXkedFJFNE1jRSettF5FsRWSkiS91l3xeRtSJSLiIN0sUqWLlEpL2IfC4im92/7dzlQ0RkgYgUicivwpT2gyKy2y33ShE5z13eQUS+FJHDIvJkPdPt5R5rvft+3uouD2u5a0i3McqcICKLRWSVm/Zv3eX9RGSRW+bX3Y4KiMhpIrJcRErdsSbhSPtFEdnmKfdod3lDf8+iRWSFiHzYWGWuJt1GKW9TaPEBHngRmNzIaZ6hqqM9/WXXAJcAXzVgGi9StVx3A7NVdRAw230NsB+4BfhzGNMG+Jtb7tGq+rG7rBC4D2iIf4BS4JeqOhQYD/xCRIYR/nJXly6Ev8xFwJmqOgoYDUwWkfHAH9y0BwEHgOvd7XcC1wGvhDFtgDs95V7pLmvo79mtwHrP68Yoc7B0oXHK2+hafIBX1a9wPoimzMN6Va3rCNzqjhmsXBcD/3af/xv4rrttpqouAUpoALV5T1U1X1Xn4QS9+qaboarL3ed5OP+EPQhzuWtIt7rtG7LMqqqH3Zex7kOBM4H/usu9Zd6uqquBquPjGy7t6rZvsO+ZiPQEzgeedV8LjVDmyunWpKH/r5pCiw/wTUCBz0RkmTjTLDSmLqqaAU5QAo4+UXzDuklEVrtNONXfgaQBiEhf4ARgEY1Y7krpQiOU2W0yWAlkAp8DW4CDquqb2SqdGn5wGjJtVfWV+xG33H8TkfgaDlFXjwF3URG0O9A4Za6crk+4y9skLMDX3gRVHQNMwTmVb/w5gJvGP4EBOKfyGcBfwpWQiCQBbwG3qWpuuNIJId1GKbOqlqnqaJzR3uOAocE2a4y0RWQEcA8wBBgLtAf+ryHTFJELgExV9U6oH9LUJmFIF8Jc3qZkAb6WVHWP+zcTeAfnH7Kx7BORbgDu3+pvbdTAVHWfGwzKgX8RpnKLSCxOkH1ZVd92F4e93MHSbawy+6jqQWAOznWAFBHxDUQM+zQfnrQnu01WqqpFwAs0fLknABeJyHbgNZymmccIf5mrpCsiMxuhvE3GAnwtiEhrEUn2PQfOwbnA2ljeB37oPv8h8F5jJewLsK7vEYZyu+2wzwHrVfWvnlVhLXd16TZSmTuJSIr7vBVwFs41gC8BX4+RsHzW1aS9wfNjKjjt4A1ablW9R1V7qmpfnClMvlDVqwhzmatJ9+pwl7dJqWqLfgCv4pw+l+C0210fxrT6A6vcx1rgXnf599y0i4B9wKxwlAunnXI2sNn9297dtqu7TS5w0H3epoHTfgn4FliNE3C7ebbfjnNR9rC7/bA6pjsR57R8NbDSfZwX7nLXkG5jlHkksMJNYw1wv+e7thhIA94E4t3lY9308oEcYG09Pufq0v7CLfcaYCaQFI7vmXvM04EPG6vM1aTbaOVt7IdNVWCMMRHKmmiMMSZCWYA3xpgIZQHeGGMilAV4Y4yJUBbgjTEmQlmAN82CO0Ojbza/vRI4i2NciMd4QUQGH2WbX4jIVQ2U53kistGTz9cb4rie46f7+qkbUxfWTdI0OyLyIHBYVf9cabngfGfrPelUQxCRecBNWjH7YEMfPx0Yoc4oU2NqzWrwplkTkYEiskZEngaWA91EZIaILBVnDvP7PdvOE5HRIhIjIgdFZLo4c50vEJHO7jYPi8htnu2nizMn+kYROcVd3lpE3nL3fdVNa3Qt8jxTRP4pIl+LyCYRmeIubyUi/xbnfgLLffMYufn9m1vO1SJyo+dwt4kzd/lqETnO3f5MN28r3eO0rufbbCKUBXjTEgwDnlPVE1R1N3C3OnPxjwLOloq5273aAnPVmet8AfDjao4tqjoOuBPw/VjcDOx1952OM7tkdV73NNFM9yzvBUwCLgRmuDMU3gIUq+rxwDXAS27z08+B7sAoVR2JM0+Kzz5VPQFnets73GV3AtPUmSTsNBpg2mITmSzAm5ZgizrzcvtcKSLLcWr0Q3F+ACorUNVP3OfLgL7VHPvtINtMxA2yquqblqI6U7XiRhF3e5a/oarl6twnYBcwyD3uS+5x1+JMpjUQZw6Yp1W1zF3nnYs/WP7mA4+JyM04Q+fLasifOYZZgDctQb7viYgMwrkjz5lubfdTICHIPsWe52VATJBtwJk/qPI2waaura3KF7e0huNKkO19quRPVR8GfgYkAUvc98SYKizAm5amDZAH5LqzAJ4bhjTmAZcDiMjxBD9DOJrvi+M4nOaazTi3dLzKPe5QoBvOxFqfAT8XkWh3XfuaDiwiA1R1tao+ijNZWI09h8yxq7pajTHN1XJgHc7Mf1txmisa2t+B/4jIaje9NcCharZ9XUQK3Of7VNX3g5OGE9A747SXF4vI34FnRORbnJk6r3WXP4PThLNaREpxbjTydA35+5WInIpzV6LVOD8QxlRh3SSNqcS96USMqha6zR+fAYO04nZyR9t/JvBfVX03nPk05misBm9MVUnAbDfQC/CzUIO7Mc2J1eCNMSZC2UVWY4yJUBbgjTEmQlmAN8aYCGUB3hhjIpQFeGOMiVD/D2THxOjpxOC4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# show plot first run\n",
    "%matplotlib inline \n",
    "# test autocompletion with tab or tab+shift\n",
    "%config IPCompleter.greedy=True \n",
    "\n",
    "random.seed(30)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "nn_img_size = 32\n",
    "num_classes = 3\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 500\n",
    "batch_size = 4\n",
    "\n",
    "loss_mode = 'mse' \n",
    "#loss_mode = 'crossentropy' \n",
    "\n",
    "loss_train_hist = []\n",
    "\n",
    "##################################################\n",
    "## Please implement a two layer neural network  ##\n",
    "##################################################\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return torch.clamp(x, min=0.0)\n",
    "\n",
    "def relu_derivative(output):\n",
    "    \"\"\"derivative of the ReLU activation function\"\"\"\n",
    "    output[output <= 0] = 0\n",
    "    output[output>0] = 1\n",
    "    return output\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"softmax function to transform values to probabilities\"\"\"\n",
    "    #print('in z:',z)\n",
    "    z -= z.max()\n",
    "    z = torch.exp(z)\n",
    "    sum_z = z.sum(1, keepdim=True)\n",
    "    #print('div z:',z / sum_z)\n",
    "    return z / sum_z \n",
    "\n",
    "def loss_mse(activation, y_batch):\n",
    "    \"\"\"mean squared loss function\"\"\"\n",
    "    # use MSE error as loss function \n",
    "    # Hint: the computed error needs to get normalized over the number of samples\n",
    "    loss = (activation - y_batch).pow(2).sum() \n",
    "    mse = 1.0 / activation.shape[0] * loss\n",
    "    return mse\n",
    "\n",
    "def loss_crossentropy(activation, y_batch):\n",
    "    \"\"\"cross entropy loss function\"\"\"\n",
    "    batch_size = y_batch.shape[0]\n",
    "    loss = ( - y_batch * activation.log()).sum() / batch_size\n",
    "    return loss\n",
    "\n",
    "def loss_deriv_mse(activation, y_batch):\n",
    "    \"\"\"derivative of the mean squared loss function\"\"\"\n",
    "    dCda2 = (1 / activation.shape[0]) * (activation - y_batch)\n",
    "    return dCda2\n",
    "\n",
    "def loss_deriv_crossentropy(activation, y_batch):\n",
    "    \"\"\"derivative of the mean cross entropy loss function\"\"\"\n",
    "    #print('activ:', activation)\n",
    "    #print('y_batch:',y_batch)\n",
    "    batch_size = y_batch.shape[0]\n",
    "    dCda2 = activation\n",
    "    dCda2[range(batch_size), np.argmax(y_batch, axis=1)] -= 1\n",
    "    dCda2 /= batch_size\n",
    "    #print('dCda2:',dCda2)\n",
    "    return dCda2\n",
    "\n",
    "def setup_train():\n",
    "    \"\"\"train function\"\"\"\n",
    "    # load and resize train images in three categories\n",
    "    # cars = 0, flowers = 1, faces = 2 ( true_ids )\n",
    "    train_images_cars = glob.glob('./images/db/train/cars/*.jpg')\n",
    "    train_images_flowers = glob.glob('./images/db/train/flowers/*.jpg')\n",
    "    train_images_faces = glob.glob('./images/db/train/faces/*.jpg')\n",
    "    train_images = [train_images_cars, train_images_flowers, train_images_faces]\n",
    "    num_rows = len(train_images_cars)+len(train_images_flowers) +len(train_images_faces)\n",
    "    X_train = torch.zeros((num_rows, nn_img_size*nn_img_size))\n",
    "    y_train = torch.zeros((num_rows, num_classes))\n",
    "\n",
    "    counter = 0\n",
    "    for (label, fnames) in enumerate(train_images):\n",
    "        for fname in fnames:\n",
    "            #print(label, fname)\n",
    "            img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (nn_img_size, nn_img_size) , interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # print( label, \" -- \", fname, img.shape)\n",
    "\n",
    "            # fill matrices X_train - each row is an image vector\n",
    "            # y_train - one-hot encoded, put only a 1 where the label is correct for the row in X_train\n",
    "            y_train[counter, label] = 1\n",
    "            X_train[counter] = torch.from_numpy(img.flatten().astype(np.float32))\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "    # print(y_train)\n",
    "    return X_train, y_train\n",
    "\n",
    "def forward(X_batch, y_batch, W1, W2, b1, b2):\n",
    "    \"\"\"forward pass in the neural network \"\"\"\n",
    "    ### YOUR CODE ####\n",
    "    # please implement the forward pass\n",
    "    # \n",
    "    #print(type(X_batch))\n",
    "    #print(type(W1))\n",
    "    #print(type(b1))\n",
    "    \n",
    "    m1 = torch.mm(X_batch, W1)+b1\n",
    "    #print(tmp.shape)\n",
    "    #m1 = torch.add(tmp,b1)\n",
    "    #print(m1.shape)\n",
    "    a1 = relu(m1)\n",
    "    #print(a1.shape)\n",
    "    \n",
    "    #m2 = torch.mm(a1, W2)+b2\n",
    "    #a2 = relu(m2)\n",
    "    \n",
    "    # if not relu(m2) in use\n",
    "    if loss_mode == 'mse':\n",
    "        a2 = torch.mm(a1, W2)+b2\n",
    "        loss = loss_mse(a2, y_batch)\n",
    "    else:\n",
    "        m2 = torch.mm(a1, W2)+b2\n",
    "        a2 = softmax(m2)\n",
    "        loss = loss_crossentropy(a2, y_batch)\n",
    "        \n",
    "    #self made\n",
    "    #loss = torch.sum((a2 - y_batch)**2)\n",
    "    \n",
    "    # the function should return the loss and both intermediate activations\n",
    "    return loss.numpy(), a2, a1\n",
    "\n",
    "def backward(a2, a1, X_batch, y_batch, W2):\n",
    "    \"\"\"backward pass in the neural network \"\"\"\n",
    "    # Implement the backward pass by computing\n",
    "    # the derivative of the complete function\n",
    "    # using the chain rule as discussed in the lecture\n",
    "    #print('a2',a2.shape)\n",
    "    #print('a1',a1.shape)\n",
    "    #print('x',X_batch.shape)\n",
    "    #print('y',y_batch.shape)\n",
    "    #print('W2',W2.shape)\n",
    "    \n",
    "    # please use the appropriate loss functions \n",
    "    # YOUR CODE HERE\n",
    "    # W1' = X.T * ( ( (2*(a2-yc)*relu(a2)) * W2.T ) * relu(a1) ) ## use relu(a2) or not??? no neg val can pass through\n",
    "    # b1' = 1 * ( ( (2*(a2-yc)*relu(a2)) * W2.T ) * relu(a1) )\n",
    "    # W2' = a1.T * 2*(a2 - yc)\n",
    "    # v2' = 1 * 2*(a2 - yc)\n",
    "    \n",
    "    dCda2 = []\n",
    "    \n",
    "    # dCostda2\n",
    "    if loss_mode == 'mse':\n",
    "        dCda2  = loss_deriv_mse(a2,y_batch)\n",
    "    else:\n",
    "        dCda2  = loss_deriv_crossentropy(a2,y_batch)\n",
    "        \n",
    "    #dCda2  = 2*(a2 - y_batch) # for W1 and W2\n",
    "    \n",
    "    #da2dm2 = relu_derivative(a2) # for W1 and W2 \n",
    "    #dm2dW2 = a1 # only for W2\n",
    "    #dm2da1 = W2 # only for W1\n",
    "    da1dm1 = relu_derivative(a1) # only for W1\n",
    "    #dm1db1 = 1 # ignore\n",
    "    #dm1dw1 = X_batch # just use X_batch\n",
    "    \n",
    "    # dCdW2 = (W2') = dCda2 * da2dm2 * dm2dW2\n",
    "    # calc in order: dCdW2 = dm2dW2 * (dCda2 * da2dm2)  \n",
    "    # fit dimension: dCdW2 = dm2dW2.T * (dCda2 * da2dm2)\n",
    "   \n",
    "    \n",
    "    # b2' = dm1db1 * dCda2 * da2dm2  # first term is 1*\n",
    "    # b2' = dCda2 * da2dm2 # mean over axis=0\n",
    "    \n",
    "    # dCdW1 = (W1') = dCda2 * da2dm2 * dm2da1 * da1dm1 * dm1dw1\n",
    "    # calc in order: dCdW1 = X_batch * [ ((dCda2 * da2dm2)*dm2da1) * da1dm1 ]\n",
    "    # fit dimension: dCdW1 = X_batch.T * [ ((dCda2 * da2dm2)*dm2da1.T) * da1dm1 ]\n",
    "    \n",
    "    # replace: dCdW2 = a1.T * (dCda2 * da2dm2)\n",
    "    #    dCdb2 = b2' = mean_over_axis0( dCda2 * da2dm2 )\n",
    "    #          dCdW1 = X_batch.T * [ ((dCda2 * da2dm2)*W2.T) * relu_derivative(a1) ]\n",
    "    #    dCdb1 = b1' = mean_over_axis0( ((dCda2 * da2dm2)*W2.T) * relu_derivative(a1) )\n",
    "    \n",
    "    # implementation\n",
    "    #tmp1 = dCda2 \n",
    "    #tmp1 = torch.mul(dCda2,da2dm2) # *relu_deriv element wise mult\n",
    "    tmp2 = torch.mm(dCda2,W2.T)\n",
    "    tmp3 = torch.mul(tmp2, da1dm1) # *relu_deriv element wise mult\n",
    "    \n",
    "    dCdW2 = torch.mm(a1.T,dCda2)\n",
    "    dCdb2 = torch.mean( dCda2, dim=0 )\n",
    "    dCdW1 = torch.mm(X_batch.T, tmp3)\n",
    "    dCdb1 = torch.mean( tmp3, dim=0 )\n",
    "    \n",
    "    # function should return 4 derivatives with respect to\n",
    "    # W1, W2, b1, b2\n",
    "    return dCdW1, dCdW2, dCdb1, dCdb2\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    \"\"\" train procedure \"\"\"\n",
    "    # for simplicity of this execise you don't need to find useful hyperparameter\n",
    "    # I've done this for you already and every test image should work for the\n",
    "    # given very small trainings database and the following parameters.\n",
    "    h = 1500\n",
    "    std = 0.001\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # initialize W1, W2, b1, b2 randomly\n",
    "    # Note: W1, W2 should be scaled by variable std\n",
    "    #W1 =  np.random.normal(0, 1.0,  h * nn_img_size**2).reshape((nn_img_size**2,h))\n",
    "    #W2 =  np.random.normal(0, 1.0,  h * num_classes).reshape((h,num_classes))\n",
    "    #W1 *= 1/(h * nn_img_size**2)\n",
    "    #W2 *= 1/(h * num_classes)\n",
    "    #print(1/(h * nn_img_size**2))\n",
    "    #print(1/(h * num_classes))\n",
    "    \n",
    "    W1 = torch.normal(torch.zeros(nn_img_size**2,h), torch.ones(nn_img_size**2,h))\n",
    "    W2 = torch.normal(torch.zeros(h,num_classes), torch.ones(h,num_classes))\n",
    "    W1 *=std\n",
    "    W2 *=std\n",
    "    # failure in predictions\n",
    "    #W1 *= 1/(h*nn_img_size**2)\n",
    "    #W2 *= 1/(h*num_classes)\n",
    "    \n",
    "    #b1 = np.random.normal(0, 0.2, h)\n",
    "    #b2 = np.random.normal(0, 0.2, num_classes)\n",
    "    b1 = torch.normal(torch.zeros(h), torch.ones(h))\n",
    "    b2 = torch.normal(torch.zeros(num_classes), torch.ones(num_classes))\n",
    "    b1 *=std\n",
    "    b2 *=std\n",
    "    #failure in predictions\n",
    "    #b1 *= 1/h\n",
    "    #b2 *= 1/num_classes\n",
    "    \n",
    "    #print(b1)\n",
    "    #print(b2)\n",
    "    \n",
    "    lenY = y_train.shape[0]\n",
    "    \n",
    "    # run for num_epochs\n",
    "    for i in range(num_epochs):\n",
    "\n",
    "        X_batch = None\n",
    "        y_batch = None\n",
    "\n",
    "        # use only a batch of batch_size of the training images in each run\n",
    "        # sample the batch images randomly from the training set\n",
    "        # YOUR CODE HERE\n",
    "        idx = random.sample(range(0, lenY), batch_size)\n",
    "        X_batch = X_train[idx]\n",
    "        y_batch = y_train[idx]\n",
    "\n",
    "        # forward pass for two-layer neural network using ReLU as activation function\n",
    "        loss, a2, a1 = forward(X_batch, y_batch, W1, W2, b1, b2)\n",
    "\n",
    "        loss_train_hist.append(loss)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "        # backward pass \n",
    "        dCdW1, dCdW2, dCdb1, dCdb2 = backward(a2, a1, X_batch, y_batch, W2)\n",
    "        \n",
    "        #print(\"dCdb2.shape:\", dCdb2.shape, dCdb1.shape)\n",
    "\n",
    "        # depending on the derivatives of W1, and W2 regaring the cost/loss\n",
    "        # we need to adapt the values in the negative direction of the \n",
    "        # gradient decreasing towards the minimum\n",
    "        # we weight the gradient by a learning rate\n",
    "        # YOUR CODE HERE\n",
    "        W1 -= learning_rate * dCdW1\n",
    "        W2 -= learning_rate * dCdW2\n",
    "        b1 -= learning_rate * dCdb1\n",
    "        b2 -= learning_rate * dCdb2\n",
    "        \n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "X_train, y_train = setup_train()\n",
    "W1, W2, b1, b2 = train(X_train, y_train)\n",
    "\n",
    "# predict the test images, load all test images and \n",
    "# run prediction by computing the forward pass\n",
    "test_images = []\n",
    "test_images.append( (cv2.imread('./images/db/test/flower.jpg', cv2.IMREAD_GRAYSCALE), 1) )\n",
    "test_images.append( (cv2.imread('./images/db/test/car.jpg', cv2.IMREAD_GRAYSCALE), 0) )\n",
    "test_images.append( (cv2.imread('./images/db/test/face.jpg', cv2.IMREAD_GRAYSCALE), 2) )\n",
    "\n",
    "for idx,ti in enumerate(test_images):\n",
    "    resized_ti = cv2.resize(ti[0], (nn_img_size, nn_img_size) , interpolation=cv2.INTER_AREA)\n",
    "    X_test = resized_ti.reshape(1,-1)\n",
    "    #print(X_test.shape)\n",
    "    # YOUR CODE HERE \n",
    "    # convert test images to pytorch\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "    # do forward pass depending mse or softmax\n",
    "    # evaluate training set accuracy\n",
    "    #print(X_test.T.size())\n",
    "    #print(W1.size())\n",
    "    hidden_layer = torch.mm(X_test,W1)\n",
    "    #print(hidden_layer.size())\n",
    "    hidden_layer[hidden_layer<0] = 0\n",
    "    a2_test = torch.mm(hidden_layer, W2)\n",
    "    \n",
    "    print(\"Test output (values / pred_id / true_id):\", a2_test, torch.argmax(a2_test), ti[1])\n",
    "    \n",
    "# print(\"------------------------------------\")\n",
    "# print(\"Test model output Weights:\", W1, W2)\n",
    "# print(\"Test model output bias:\", b1, b2)\n",
    "\n",
    "#print(np.asarray(loss_train_hist))\n",
    "\n",
    "plt.title(\"Training Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel('Training Loss '+loss_mode)\n",
    "plt.plot(range(1,num_epochs +1),loss_train_hist,label=\"Train\")\n",
    "plt.ylim((0,5.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 50.0))\n",
    "plt.legend()\n",
    "plt.savefig('simple_nn_train_'+loss_mode+'.png')\n",
    "plt.show()\n",
    "\n",
    "#plt.title(\"Training Loss vs. Number of Training Epochs\")\n",
    "#plt.xlabel(\"Training Epochs\")\n",
    "#plt.ylabel(\"Training Loss Cross\")\n",
    "#plt.plot(range(1,num_epochs +1),loss_cross_train_hist,label=\"Train\")\n",
    "#plt.ylim((0,5.))\n",
    "#plt.xticks(np.arange(1, num_epochs+1, 50.0))\n",
    "#plt.legend()\n",
    "#plt.savefig(\"simple_nn_train_cross.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
